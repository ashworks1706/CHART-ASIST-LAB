{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Modal Data Analysis Workflow\n",
    "\n",
    "**ASIST Study 3 Dataset**\n",
    "\n",
    "#### **Team 000286 Pre-Result Analysis**\n",
    "\n",
    "Engineer exibited poor skill during the hands on training. It took him a very long time to complete the individual training which resulted in the mission timer running out during the team training section. Once the timer expired, the hands-on training trial was restarted and participants again completed the individual training. Engineer's second attempt still took over 5 minutes to complete individual training. The competency test was then started at 13m remaining on the timer, the engineer took a full 5 minutes to complete the competency test. Experiment team decided that engineer should be allowed to proceed to avoid rescheduling dispite the evident lack of minecraft skill.\n",
    "\n",
    "## Objective\n",
    "\n",
    "Analyze team performance data across four modalities:\n",
    "\n",
    "1. JSON behavior logs\n",
    "2. Video recordings\n",
    "3. Chat transcripts\n",
    "\n",
    "Identify correlations between AI interventions and team outcomes.\n",
    "\n",
    "## Note\n",
    "\n",
    "All datasets were taken from official CHART ASIST Study 3 Dataset available at ASU official repository.\n",
    "\n",
    "#### Subset used :\n",
    "\n",
    "| Team ID | ASI ID        | trial   | intervention_recipent     |\n",
    "| ------- | ------------- | ------- | ------------------------- |\n",
    "| 000286  | ASI-CMURI-TA1 | T000829 | E001211, E001215, E001155 |\n",
    "\n",
    "\n",
    "\n",
    "**AI Agent Action signals** -\n",
    "\n",
    "1. RemindTransporterBeep\n",
    "2. InformAboutTriagedVictim\n",
    "3. RemindMedicToInformAboutTriagedVicti\n",
    "4. TriageCriticalVictim\n",
    "5. EvacuateCriticalVictim\n",
    "6. EncouragePlayerProximityToMedicIHMCDyad\n",
    "7. RemindChangeMarke\n",
    "8. RemindRubblePerturbatio\n",
    "9. EvacuationZoneDistanc\n",
    "10. TeamSawVictimMarke\n",
    "11. TimeElapse\n",
    "12. StartEvacuatio\n",
    "\n",
    "**Agents location**-\n",
    "\n",
    "1. Location of the agent in the map -> Room Name\n",
    "\n",
    "**Agent Action**-\n",
    "\n",
    "1. Transporting victims\n",
    "2. Performing their role task including stabilizing victims\n",
    "3. wakening up critical victims\n",
    "4. placing marking block-> Regular, A, B, C\n",
    "5. placing marking block for threat rooms\n",
    "6. removing rubbles\n",
    "7. detecting victims\n",
    "\n",
    "## Manual Dataframe\n",
    "\n",
    "Timestamp, AI Message, AI Action Class, Transporter Message, Engineer Message, Medic Message is extracted from transcript.csv\n",
    "\n",
    "We use Multimodal LLM analysis to analyze video data to give states and locations of agents + victims throughout the experiment\n",
    "\n",
    "\n",
    "| Time Stamp (Transcript) | Asi Message (Transcript) | Asi Action Class (Transcript) | Transporter Message (Transcript) | Engineer Message (Transcript) | Medic Message (Transcript) |\n",
    "| ----------------------- | ------------------------ | ----------------------------- | ------------------------------- | ----------------------------- | -------------------------- |\n",
    "| 11:23:01                | N/A                      | N/A                           | N/A                             | N/A                           | N/A                        |\n",
    "\n",
    "## llmv1 Dataframe\n",
    "\n",
    "States tells us what the agent is doing\n",
    "Locations tells use where the agent is located in the map\n",
    "\n",
    "States and locations are fused together using LLM analysis to form one action_state column signifying their role in a situation\n",
    "\n",
    "| timestamp (Transcript) | asi_reason (Transcript) | asi_action (Transcript) | transporter_message (Transcript) | engineer_message (Transcript) | medic_message (Transcript) | transporter_action_state (LLM) | engineer_action_state (LLM) | medic_action_state (LLM) | victim_location (LLM) | \n",
    "| --------- | --------- | --------- | ------------------ | --------------- | ------------ | --------------- | --------------- | ------------ | --------------- |\n",
    "|           |           |           |                    |                 |              |                 |                 |              |                 |\n",
    "\n",
    "\n",
    "We then utilize another LLM to finally provide ASI Advice score and team score for their actions and LLM's reasoning behiind that\n",
    "\n",
    "## llmv2 Dataframe\n",
    "| timestamp (Transcript) | asi_reason (Transcript) | asi_action (Transcript) | transporter_message (Transcript) | engineer_message (Transcript) | medic_message (Transcript) | transporter_action_state (LLM) | engineer_action_state (LLM) | medic_action_state (LLM) | victim_location (LLM) | team_score (LLM) | asi_advice_score (LLM) | team_score_reason (LLM) | asi_advice_score_reason (LLM)\n",
    "| --------- | --------- | --------- | ------------------ | --------------- | ------------ | --------------- | ---------- | --------------- | --------------- |--------------- |--------------- | --------------- | --------------- |\n",
    "|     22:03      |   You guys should do [asi_action_class] because...        | 1. RemindTransporterBeep <br/>2. InformAboutTriagedVictim <br/>3. RemindMedicToInformAboutTriagedVicti <br/>4. TriageCriticalVictim <br/>5. EvacuateCriticalVictim <br/>6.EncouragePlayerProximityToMedicIHMCDyad <br/>7. RemindChangeMarke <br/>8. RemindRubblePerturbatio <br/>9. EvacuationZoneDistanc <br/>10. TeamSawVictimMarke <br/>11. TimeElapse <br/>12. StartEvacuatio|     I'm coming for you medic               |     This is more important               |     I can't help you!               |     Carrying a victim from b4 to B2 room               |     Clearing rubbles in threat room for medic  at a9 room          |     waking up critical victim at g5 room        |    next to medic, far from engineer, close to transporter            |  40%          |     75%           | team was inconsistent with their tasks, especially... | asi's advice is particularly useful because... |\n",
    "\n",
    "\n",
    "## AI Instruct Modal\n",
    "\n",
    "We finetune pretrained LLM on our data for understanding minecraft test bed for asist thoroughly and deeply. Then we utilize it to perform-\n",
    "\n",
    "1. **Multimodal DataAnalysis of Video Data** \n",
    "\n",
    "To give information about agent locations and their actions\n",
    "\n",
    "2. **Text Fusion Data Analysis**\n",
    "\n",
    "To fuse meanings and relationships between agent communication, their location and state in given situations to a single column\n",
    "\n",
    "3. **Scoring Analysis**\n",
    "\n",
    "To score humans and ASI's advice on team work communication and collaboration data   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "# import openai\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "# import torch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch GEMINI_API_KEY\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. JSON Logs Processing\n",
    "#### Objective\n",
    "Extract structured data from nested JSON logs containing:\n",
    "- Team actions\n",
    "- AI intervention timestamps\n",
    "- Mission outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def parse_json_logs(input_path: Path, output_path: Path) -> pd.DataFrame:\n",
    "#     \"\"\"Flatten nested JSON logs into structured format\"\"\"\n",
    "#     with open(input_path, 'r') as f:\n",
    "#         data = [json.loads(line) for line in f]\n",
    "    \n",
    "#     df = pd.json_normalize(data, sep='_')\n",
    "#     df.to_csv(output_path, index=False)\n",
    "#     return df\n",
    "\n",
    "# # Process all trial messages\n",
    "# input_files = [\n",
    "#     Path(\"data/json_logs/HSRData_TrialMessages_Trial-T000603_...\"),\n",
    "#     Path(\"data/json_logs/HSRData_TrialMessages_Trial-T000639_...\"),\n",
    "#     Path(\"data/json_logs/HSRData_TrialMessages_Trial-T000671_...\")\n",
    "# ]\n",
    "\n",
    "# output_dir = Path(\"data/processed/json_parsed/\")\n",
    "# output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# for file in input_files:\n",
    "#     output_file = output_dir / f\"{file.stem}_parsed.csv\"\n",
    "#     df = parse_json_logs(file, output_file)\n",
    "#     print(f\"Processed {len(df)} records from {file.name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective \n",
    "\n",
    "Finetune the pretrained instruct model on testbed refined high quality data and information about agents, environment, locations. \n",
    "\n",
    "\n",
    "1. Transporting victims\n",
    "2. Performing their role task including stabilizing victims\n",
    "3. wakening up critical victims\n",
    "4. placing marking block-> Regular, A, B, C\n",
    "5. placing marking block for threat rooms\n",
    "6. removing rubbles\n",
    "7. detecting victims\n",
    "\n",
    "![image.png](chart_study3_guide/blocks.png)\n",
    "\n",
    "\n",
    "![image.png](chart_study3_guide/map.png)\n",
    "\n",
    "\n",
    "\n",
    "[ Maybe : Train model to understand video data as well ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineer Instruct POV Model\n",
    "\n",
    "Finetune the pretrained instruct model on testbed refined high quality data and information about agents actions in minecraft video. \n",
    "\n",
    "#### Possible Actions\n",
    "\n",
    "1. Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \n",
    "2. Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\n",
    "3. Destroying rubles for making way for rescue teammates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineer POV model instruction (focusing only on in-game actions)\n",
    "engineer_pov_model_instruction = \"\"\"You are a professional Minecraft Engineer Agent Activity analyzer. You only have to log what the agent is doing in their first-person view. DO NOT listen to what they're saying. Follow this guideline thoroughly to log any of these important details which are happening in the video every 3 seconds of the video. \n",
    "\n",
    "1. The Minecraft Agent POV Video:\n",
    " - The video shows what the Engineer agent is doing in first-person view. The Engineer's job is to work together with a medic and transporter to save victims in a Minecraft rescue simulation. Key events to document:\n",
    "    a) Placing Avatar Yellow Marker Block for notifying there's a victim nearby\n",
    "    b) Placing Blank Yellow Marker Block for notifying there's a threat room nearby\n",
    "    c) Placing Avatar Red Marker Block for notifying there's a critical victim nearby\n",
    "    d) Placing Avatar Blue Marker Block for notifying there's a regular victim nearby\n",
    "    e) Placing Blank Red Marker Block for notifying there's rubble nearby\n",
    "    f) Placing Blank Blue Marker Block for notifying there's a help request nearby\n",
    "    g) Destroying rubbles for making way for rescue teammates\n",
    "    h) Interacting with any blocks or items\n",
    "    i) Moving through hallways or rooms\n",
    "    j) Encountering other players (the Engineer wears blue skin, medic wears red, and the transporter wears green skin)\n",
    "\n",
    "2. Logging Instructions:\n",
    " - Log the agent's activity every 3 seconds in JSON format\n",
    " - If no key event occurs, log that \"nothing significant is happening\"\n",
    " - Example JSON Response:\n",
    "    [{timestamp: \"00:03\", \"text\":\"Engineer destroyed rubble\"},\n",
    "     {timestamp: \"00:06\", \"text\":\"Engineer placed a critical victim marker\"},\n",
    "     {timestamp: \"00:09\", \"text\":\"Engineer placed a help request marker\"}]\n",
    "\"\"\"\n",
    "\n",
    "# Engineer Location model instruction (focusing only on map location)\n",
    "engineer_location_model_instruction = \"\"\"You are a professional Minecraft Agent Location tracker. You only have to track where the agent is on the map view. Follow this guideline thoroughly to log the location details every 3 seconds of the video.\n",
    "\n",
    "1. The Location Map Video:\n",
    " - The video shows a map view with a blue dot representing the Engineer agent. Your job is to track this blue dot and report its position. Key points:\n",
    "    a) Location of the agent throughout the map across various zones\n",
    "    b) Movement between rooms or zones\n",
    "    c) Time spent in specific locations\n",
    "\n",
    "2. Map Details:\n",
    " - The map is divided into several zones labeled as N Zone A, N Zone B, N Zone C, S Zone A, S Zone B, and S Zone C\n",
    " - Each zone contains subzones labeled with alphanumeric identifiers (e.g., A1, B2, C3, etc.)\n",
    " - Key landmarks:\n",
    "    - Yellow markers indicate victims or threats\n",
    "    - Red markers indicate critical victims or rubble\n",
    "    - Blue markers indicate regular victims or help requests\n",
    "\n",
    "3. Logging Instructions:\n",
    " - Log the blue dot's position every 3 seconds in JSON format\n",
    " - Note any zone transitions or prolonged stays in one location\n",
    " - Example JSON Response:\n",
    "    [{timestamp: \"00:03\", \"text\":\"Engineer in A2 Zone\"},\n",
    "     {timestamp: \"00:06\", \"text\":\"Engineer moving from A2 Zone to B2 Zone\"},\n",
    "     {timestamp: \"00:09\", \"text\":\"Engineer stationary in B2 Zone\"}]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medic Instruct POV \n",
    "\n",
    "Finetune the pretrained instruct model on testbed refined high quality data and information about agents actions in minecraft video. \n",
    "\n",
    "1. Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \n",
    "2. Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\n",
    "3. Stabilizing avatar victim blocks turning into safe blocks.\n",
    "4. Stabilizing avatar victim blocks turning into X blocks notifying victim is dead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "medic_pov_model_instruction = \"\"\"You are a professional Minecraft Medic Agent Activity analyzer. You only have to log what the agent is doing in their first-person view. DO NOT listen to what they're saying. Follow this guideline thoroughly to log any of these important details which are happening in the video every 3 seconds of the video.\n",
    "\n",
    "1. The Minecraft Agent POV Video:\n",
    " - The video shows what the Medic agent is doing in first-person view. The Medic's job is to work together with an engineer and transporter to save victims in a Minecraft rescue simulation. Key events to document:\n",
    "    a) Placing Avatar Yellow Marker Block for notifying there's a victim nearby\n",
    "    b) Placing Blank Yellow Marker Block for notifying there's a threat room nearby\n",
    "    c) Placing Avatar Red Marker Block for notifying there's a critical victim nearby\n",
    "    d) Placing Avatar Blue Marker Block for notifying there's a regular victim nearby\n",
    "    e) Stabilizing avatar victim blocks turning into safe blocks\n",
    "    f) Stabilizing avatar victim blocks turning into X blocks notifying victim is dead\n",
    "    g) Moving through hallways or rooms\n",
    "    h) Encountering other players (the Medic wears red skin, engineer wears blue, and the transporter wears green skin)\n",
    "\n",
    "2. Logging Instructions:\n",
    " - Log the agent's activity every 3 seconds in JSON format\n",
    " - If no key event occurs, log that \"nothing significant is happening\"\n",
    " - Example JSON Response:\n",
    "    [{timestamp: \"00:03\", \"text\":\"Medic stabilized a victim\"},\n",
    "     {timestamp: \"00:06\", \"text\":\"Medic placed a critical victim marker\"},\n",
    "     {timestamp: \"00:09\", \"text\":\"Medic encountered the engineer\"}]\n",
    "\"\"\"\n",
    "\n",
    "# New model instruction for location analysis\n",
    "medic_location_model_instruction = \"\"\"You are a professional Minecraft Agent Location tracker. You only have to track where the agent is on the map view. Follow this guideline thoroughly to log the location details every 3 seconds of the video.\n",
    "\n",
    "1. The Location Map Video:\n",
    " - The video shows a map view with a red dot representing the Medic agent. Your job is to track this red dot and report its position. Key points:\n",
    "    a) Location of the agent throughout the map across various zones\n",
    "    b) Movement between rooms or zones\n",
    "    c) Time spent in specific locations\n",
    "\n",
    "2. Map Details:\n",
    " - The map is divided into several zones labeled as N Zone A, N Zone B, N Zone C, S Zone A, S Zone B, and S Zone C\n",
    " - Each zone contains subzones labeled with alphanumeric identifiers (e.g., A1, B2, C3, etc.)\n",
    " - Key landmarks:\n",
    "    - Yellow markers indicate victims or threats\n",
    "    - Red markers indicate critical victims or rubble\n",
    "    - Blue markers indicate regular victims or help requests\n",
    "\n",
    "3. Logging Instructions:\n",
    " - Log the red dot's position every 3 seconds in JSON format\n",
    " - Note any zone transitions or prolonged stays in one location\n",
    " - Example JSON Response:\n",
    "    [{timestamp: \"00:03\", \"text\":\"Medic in C2 Zone\"},\n",
    "     {timestamp: \"00:06\", \"text\":\"Medic moving from C2 Zone to B2 Zone\"},\n",
    "     {timestamp: \"00:09\", \"text\":\"Medic stationary in B2 Zone\"}]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transporter Instruct POV Model\n",
    "\n",
    "\n",
    "Finetune the pretrained instruct model on testbed refined high quality data and information about agents actions in minecraft video. \n",
    "\n",
    "\n",
    "1. Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \n",
    "2. Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\n",
    "3. Transporting victims from location to location.\n",
    "4. Standing on wifi signal block to detect victims nearby.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transporter_pov_model_instruction = \"\"\"You are a professional Minecraft Transporter Agent Activity analyzer. You only have to log what the agent is doing in their first-person view. DO NOT listen to what they're saying. Follow this guideline thoroughly to log any of these important details which are happening in the video every 3 seconds of the video.\n",
    "\n",
    "1. The Minecraft Agent POV Video:\n",
    " - The video shows what the Transporter agent is doing in first-person view. The Transporter's job is to work together with an engineer and medic to save victims in a Minecraft rescue simulation. Key events to document:\n",
    "    a) Placing Avatar Yellow Marker Block for notifying there's a victim nearby\n",
    "    b) Placing Blank Yellow Marker Block for notifying there's a threat room nearby\n",
    "    c) Placing Avatar Red Marker Block for notifying there's a critical victim nearby\n",
    "    d) Placing Avatar Blue Marker Block for notifying there's a regular victim nearby\n",
    "    e) Placing Blank Red Marker Block for notifying there's rubble nearby\n",
    "    f) Placing Blank Blue Marker Block for notifying there's a help request nearby\n",
    "    g) Transporting victims from location to location\n",
    "    h) Standing on wifi signal block to detect victims nearby\n",
    "    i) Moving through hallways or rooms\n",
    "    j) Encountering other players (the Transporter wears green skin, engineer wears blue, and the medic wears red skin)\n",
    "\n",
    "2. Logging Instructions:\n",
    " - Log the agent's activity every 3 seconds in JSON format\n",
    " - If no key event occurs, log that \"nothing significant is happening\"\n",
    " - Example JSON Response:\n",
    "    [{timestamp: \"00:03\", \"text\":\"Transporter picked up a victim\"},\n",
    "     {timestamp: \"00:06\", \"text\":\"Transporter placed a critical victim marker\"},\n",
    "     {timestamp: \"00:09\", \"text\":\"Transporter standing on wifi signal block\"}]\n",
    "\"\"\"\n",
    "\n",
    "# New model instruction for location analysis\n",
    "transporter_location_model_instruction = \"\"\"You are a professional Minecraft Agent Location tracker. You only have to track where the agent is on the map view. Follow this guideline thoroughly to log the location details every 3 seconds of the video.\n",
    "\n",
    "1. The Location Map Video:\n",
    " - The video shows a map view with a green dot representing the Transporter agent. Your job is to track this green dot and report its position. Key points:\n",
    "    a) Location of the agent throughout the map across various zones\n",
    "    b) Movement between rooms or zones\n",
    "    c) Time spent in specific locations\n",
    "\n",
    "2. Map Details:\n",
    " - The map is divided into several zones labeled as N Zone A, N Zone B, N Zone C, S Zone A, S Zone B, and S Zone C\n",
    " - Each zone contains subzones labeled with alphanumeric identifiers (e.g., A1, B2, C3, etc.)\n",
    " - Key landmarks:\n",
    "    - Yellow markers indicate victims or threats\n",
    "    - Red markers indicate critical victims or rubble\n",
    "    - Blue markers indicate regular victims or help requests\n",
    "\n",
    "3. Logging Instructions:\n",
    " - Log the green dot's position every 3 seconds in JSON format\n",
    " - Note any zone transitions or prolonged stays in one location\n",
    " - Example JSON Response:\n",
    "    [{timestamp: \"00:03\", \"text\":\"Transporter in B2 Zone\"},\n",
    "     {timestamp: \"00:06\", \"text\":\"Transporter moving from B2 Zone to C3 Zone\"},\n",
    "     {timestamp: \"00:09\", \"text\":\"Transporter stationary in C3 Zone\"}]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Admin Instruct Model (Obsolete)\n",
    "\n",
    "\n",
    "Finetune the pretrained instruct model on testbed refined high quality data and information about victim locations and agent locations in live map. \n",
    "\n",
    "[ Maybe : Train model to understand video data as well ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# admin_model_instruction = \"\"\"You are a professional Minecraft Testbed Agents Activity analyzer. You only have to log where the agents are. DO NOT listen to what they're saying. Follow this guideline thoroughly to log any of these important details which are happening in the video every 3 seconds of the video. Here are all important things to consider - \\n- 1. Testbed Map :\\n - The map is devided into four zones - A,B,C and D that have many rooms   \\n It's not neccessary that every second there will be a key event so you can just say that nothing is happening in the video. Example JSON Response -\\n[{timestamp: \"00:03\", \"text\":\"Transporter went into A2 Zone\"},{timestamp: \"00:06\", \"text\":\"Transporter carried a victim from A2 Zone to A2 Zone\"},{timestamp: \"00:09\", \"text\":\"Transporter placed marker block\"},]\\n[{timestamp: \"00:03\", \"text\":\"Transporter is walking\"},{timestamp: \"00:06\", \"text\":\"Transporter stayed at same location for long\"},{timestamp: \"00:09\", \"text\":\"Transporter did nothing\"}]\"\"\"\n",
    "# admin_model_instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player's Action State Fusor Model\n",
    "\n",
    "\n",
    "Fuses player actions and their location in maps to form a rich action state data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a professional context summarizer. Your job is to analyze a data having two properties which is action and state. You have to summarize the data into a single sentence. The data is about a minecraft test bed rescue simulation where three agents named Engineer, Medic and Transporter work and communicate with each other to rescue victims from threat rooms. Here is some information about the agents :\\n1. Engineer : Engineer agent wears blue skin while medic wears red and transporter wears green skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there\\'s a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there\\'s a threat room nearby for others to be aware.\\nc) Destroying rubles for making way for rescue teammates.\\n2. Transporter :  Transporter agent wears green skin while engineer wears blue and medic wears red skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there\\'s a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there\\'s a threat room nearby for others to be aware.\\nc) Transporting victims from location to location.\\nd) Standing on wifi signal block to detect victims nearby.\\n3. Medic : Medic agent wears red skin while engineer wears blue and transporter wears green skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there\\'s a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there\\'s a threat room nearby for others to be aware.\\nc) Stabilizing avatar victim blocks turning into safe blocks\\nd) Stabilizing avatar victim blocks turning into X blocks notifying victim is dead. \\nHere are all important things to consider - \\n- 1. Action : \\n - The action is what the agent might be doing or did in their task during the environment mission. \\n- 2. Communication : \\n - The communication transmitted from agent in the video shared with either of medic, transporter or engineer. \\n It\\'s not neccessary that every second there will be a key event so you can just say that nothing is happening in the video. Example JSON Response -\\n{timestamp: \"00:03\", \"action_state\":\"Engineer went into A2 Zone to help medic and destroyed rubble\"},{timestamp: \"00:09\", \"action_state\":\"Medic was just communicating but did nothing from its side\"}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_state_fusor_model_instruction = \"\"\"You are a professional context summarizer. Your job is to analyze a data having two properties which is action and state. You have to summarize the data into a single sentence. The data is about a minecraft test bed rescue simulation where three agents named Engineer, Medic and Transporter work and communicate with each other to rescue victims from threat rooms. Here is some information about the agents :\\n1. Engineer : Engineer agent wears blue skin while medic wears red and transporter wears green skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\\nc) Destroying rubles for making way for rescue teammates.\\n2. Transporter :  Transporter agent wears green skin while engineer wears blue and medic wears red skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\\nc) Transporting victims from location to location.\\nd) Standing on wifi signal block to detect victims nearby.\\n3. Medic : Medic agent wears red skin while engineer wears blue and transporter wears green skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\\nc) Stabilizing avatar victim blocks turning into safe blocks\\nd) Stabilizing avatar victim blocks turning into X blocks notifying victim is dead. \\nHere are all important things to consider - \\n- 1. Action : \\n - The action is what the agent might be doing or did in their task during the environment mission. \\n- 2. Communication : \\n - The communication transmitted from agent in the video shared with either of medic, transporter or engineer. \\n It's not neccessary that every second there will be a key event so you can just say that nothing is happening in the video. Example JSON Response -\\n{timestamp: \"00:03\", \"action_state\":\"Engineer went into A2 Zone to help medic and destroyed rubble\"},{timestamp: \"00:09\", \"action_state\":\"Medic was just communicating but did nothing from its side\"}\"\"\"\n",
    "action_state_fusor_model_instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Model\n",
    "\n",
    "Consideres all important data and gives score to each intervention's team and asi advice with reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a professional teamwork scorer. Your job is to analyze a data having various properties of the data to give . You have to rate the team work score to the team, You have to be impartial and a critique like a professional. The data is about a minecraft test bed rescue simulation where three agents named Engineer, Medic and Transporter work and communicate with each other to rescue victims from threat rooms. Here is some information about the agents :\\n1. Engineer : Engineer agent wears blue skin while medic wears red and transporter wears green skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there\\'s a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there\\'s a threat room nearby for others to be aware.\\nc) Destroying rubles for making way for rescue teammates.\\n2. Transporter :  Transporter agent wears green skin while engineer wears blue and medic wears red skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there\\'s a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there\\'s a threat room nearby for others to be aware.\\nc) Transporting victims from location to location.\\nd) Standing on wifi signal block to detect victims nearby.\\n3. Medic : Medic agent wears red skin while engineer wears blue and transporter wears green skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there\\'s a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there\\'s a threat room nearby for others to be aware.\\nc) Stabilizing avatar victim blocks turning into safe blocks\\nd) Stabilizing avatar victim blocks turning into X blocks notifying victim is dead. \\nHere are all important things to consider - \\n- 1. Action : \\n - The action is what the agent might be doing or did in their task during the environment mission. \\n- 2. Communication : \\n - The communication transmitted from agent in the video shared with either of medic, transporter or engineer. Example JSON Response -\\n{timestamp: \"00:03\", \"team_score\":\"76\", \"reason:\" \"Engineer went into A2 Zone to help medic and destroyed rubble, Medic stabilized a victim and rushed to transporter, very quickly in this way the team work was good\"}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_model_instruction = \"\"\"You are a professional teamwork scorer. Your job is to analyze a data having various properties of the data to give . You have to rate the team work score to the team, You have to be impartial and a critique like a professional. The data is about a minecraft test bed rescue simulation where three agents named Engineer, Medic and Transporter work and communicate with each other to rescue victims from threat rooms. Here is some information about the agents :\\n1. Engineer : Engineer agent wears blue skin while medic wears red and transporter wears green skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\\nc) Destroying rubles for making way for rescue teammates.\\n2. Transporter :  Transporter agent wears green skin while engineer wears blue and medic wears red skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\\nc) Transporting victims from location to location.\\nd) Standing on wifi signal block to detect victims nearby.\\n3. Medic : Medic agent wears red skin while engineer wears blue and transporter wears green skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\\nc) Stabilizing avatar victim blocks turning into safe blocks\\nd) Stabilizing avatar victim blocks turning into X blocks notifying victim is dead. \\nHere are all important things to consider - \\n- 1. Action : \\n - The action is what the agent might be doing or did in their task during the environment mission. \\n- 2. Communication : \\n - The communication transmitted from agent in the video shared with either of medic, transporter or engineer. Example JSON Response -\\n{timestamp: \"00:03\", \"team_score\":\"76\", \"reason:\" \"Engineer went into A2 Zone to help medic and destroyed rubble, Medic stabilized a victim and rushed to transporter, very quickly in this way the team work was good\"}\"\"\"\n",
    "scoring_model_instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcript.csv analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/ash/CHART ASIST/data/transcripts/TM000297.csv\")\n",
    "df = df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Intervention Message</th>\n",
       "      <th>Intervention Recipient</th>\n",
       "      <th>Speech Message</th>\n",
       "      <th>Medic</th>\n",
       "      <th>Transporter</th>\n",
       "      <th>Engineer</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>22:27:34</td>\n",
       "      <td>Hello, I am ATLAS, and will be providing advic...</td>\n",
       "      <td>['E001001', 'E001146', 'E001064']</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'info': {'intervention_class': 'TeamWelcomeMe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>22:27:55</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>people is be advised there is some wield damag...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>22:28:06</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>okay so this is medic my plan is I'm going to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>22:28:07</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>22:28:10</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>copy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Timestamp                               Intervention Message  \\\n",
       "1  2022-06-27  22:27:34  Hello, I am ATLAS, and will be providing advic...   \n",
       "2  2022-06-27  22:27:55                                                 {}   \n",
       "3  2022-06-27  22:28:06                                                 {}   \n",
       "4  2022-06-27  22:28:07                                                 {}   \n",
       "5  2022-06-27  22:28:10                                                 {}   \n",
       "\n",
       "              Intervention Recipient  \\\n",
       "1  ['E001001', 'E001146', 'E001064']   \n",
       "2                                 {}   \n",
       "3                                 {}   \n",
       "4                                 {}   \n",
       "5                                 {}   \n",
       "\n",
       "                                      Speech Message  Medic  Transporter  \\\n",
       "1                                                 {}      1            1   \n",
       "2  people is be advised there is some wield damag...      0            0   \n",
       "3  okay so this is medic my plan is I'm going to ...      1            0   \n",
       "4                                                yes      0            1   \n",
       "5                                               copy      0            0   \n",
       "\n",
       "   Engineer                                        Explanation  \n",
       "1         1  {'info': {'intervention_class': 'TeamWelcomeMe...  \n",
       "2         1                                                 {}  \n",
       "3         0                                                 {}  \n",
       "4         0                                                 {}  \n",
       "5         1                                                 {}  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Data\n",
    "\n",
    "Originally it had many columns and we reduced it down to only the ones which had data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'intervention_message'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'intervention_message'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33masi_message\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mintervention_message\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.replace(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mteam_message\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mspeech_message\u001b[39m\u001b[33m\"\u001b[39m].replace(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/venv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'intervention_message'"
     ]
    }
   ],
   "source": [
    "df[\"asi_message\"] = df[\"intervention_message\"].replace(\"{}\", \"\")\n",
    "df[\"team_message\"] = df[\"speech_message\"].replace(\"{}\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a intervention_class column from explanation string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract intervention_class from explanation strings\n",
    "df['intervention_class'] = df['explanation'].str.extract(\n",
    "    r\"'intervention_class'\\s*:\\s*'([^']*)'\"\n",
    ")\n",
    "\n",
    "# Create binary columns for each unique intervention class\n",
    "intervention_classes = df['intervention_class'].dropna().unique()\n",
    "for cls in intervention_classes:\n",
    "    df[cls] = df['intervention_class'].eq(cls).astype(int)\n",
    "\n",
    "# Cleanup intermediate column\n",
    "df = df.drop(columns=['intervention_class'])\n",
    "\n",
    "# Clean column names by removing 'Intervention' suffix\n",
    "df = df.rename(columns=lambda col: col[:-13] if col.endswith('Intervention') else col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need unique team ids, asi ids, date, trial id, intervention_recipent id or explanation since we have extracted the unique class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop(columns=[\"team\",\"asi\",\"date\",\"intervention_recipent\",\"intervention_message\",\"speech_message\",\"trial\"], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Drop duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player's POV LLM Data Analysis - Multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Gemini [Multimodal book](https://colab.research.google.com/drive/1eXv-lpq9Lp4s2Vf2ISmSEngMJnVMOBRk?usp=sharing#scrollTo=A0zpRFCI-weC) to setup instruct models for [analysis](https://aistudio.google.com/app/starter-apps/video)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp\n",
    "\n",
    "df = pd.read_csv(\"/mnt/c/Users/Som/Desktop/CHART ASIST/temp.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Player model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with video: data/video/TM000297/experiment_1/engineer/pov/chunk_1/chunk_1.mp4\n",
      "File uploaded: files/84c4sw8rv94l\n",
      "File state: FileState.PROCESSING\n",
      "Waiting for file processing...\n",
      "File state: FileState.ACTIVE\n",
      "File is now active and ready for processing\n",
      "Response received:\n",
      "[\n",
      "  {\"timestamp\": \"00:00\", \"text\": \"Engineer is moving through a hallway\"},\n",
      "  {\"timestamp\": \"00:03\", \"text\": \"Engineer is moving through a hallway\"},\n",
      "  {\"timestamp\": \"00:06\", \"text\": \"Engineer is moving through a hallway\"}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "from google import genai\n",
    "from google.genai.types import GenerateContentConfig, HttpOptions\n",
    "\n",
    "# Initialize the client\n",
    "genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "MODEL_ID = 'gemini-2.0-flash-exp'\n",
    "\n",
    "# Define a test video path - use a specific video file that exists\n",
    "test_video_path = Path(\"data/video/TM000297/experiment_1/engineer/pov/chunk_1/chunk_1.mp4\")\n",
    "\n",
    "# Test if the file exists\n",
    "if not test_video_path.exists():\n",
    "    print(f\"Test video not found: {test_video_path}\")\n",
    "else:\n",
    "    try:\n",
    "        print(f\"Testing with video: {test_video_path}\")\n",
    "        \n",
    "        # Upload the video to Gemini\n",
    "        file_upload = genai_client.files.upload(file=str(test_video_path))\n",
    "        print(f\"File uploaded: {file_upload.name}\")\n",
    "        \n",
    "        # Wait for file to be processed (ACTIVE state)\n",
    "        max_retries = 10\n",
    "        retry_count = 0\n",
    "        while retry_count < max_retries:\n",
    "            # Check file status\n",
    "            file_info = genai_client.files.get(name=file_upload.name)\n",
    "            print(f\"File state: {file_info.state}\")\n",
    "            \n",
    "            if file_info.state == \"ACTIVE\":\n",
    "                print(f\"File is now active and ready for processing\")\n",
    "                break\n",
    "            \n",
    "            print(\"Waiting for file processing...\")\n",
    "            time.sleep(5)\n",
    "            retry_count += 1\n",
    "        \n",
    "        if retry_count == max_retries:\n",
    "            print(\"File processing timed out\")\n",
    "        else:\n",
    "            # Generate content with a simplified instruction\n",
    "            test_instruction = \"Please Follow the guidelines. Here is the video. RESPOND IN JSON FORMAT ONLY.\"\n",
    "            \n",
    "            response = genai_client.models.generate_content(\n",
    "                model=MODEL_ID,\n",
    "                config=GenerateContentConfig(\n",
    "                    system_instruction=[engineer_pov_model_instruction]\n",
    "                ),\n",
    "                contents=[\n",
    "                    {\"role\": \"user\", \"parts\": [\n",
    "                        {\"file_data\": {\"file_uri\": file_upload.uri, \"mime_type\": \"video/mp4\"}},\n",
    "                        {\"text\": test_instruction}\n",
    "                    ]}\n",
    "                ]\n",
    "            )\n",
    "            response_text= response.text\n",
    "            if \"```json\" in response_text:\n",
    "                response_text = response.text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            \n",
    "            print(\"Response received:\")\n",
    "            print(response_text)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in test script: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Location test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "from google import genai\n",
    "from google.genai.types import GenerateContentConfig, HttpOptions\n",
    "\n",
    "# Initialize the client\n",
    "genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "MODEL_ID = 'gemini-2.0-flash-exp'\n",
    "\n",
    "# Define a test video path - use a specific video file that exists\n",
    "test_video_path = Path(\"data/video/TM000297/experiment_1/engineer/location/chunk_1/chunk_1.mp4\")\n",
    "\n",
    "# Test if the file exists\n",
    "if not test_video_path.exists():\n",
    "    print(f\"Test video not found: {test_video_path}\")\n",
    "else:\n",
    "    try:\n",
    "        print(f\"Testing with video: {test_video_path}\")\n",
    "        \n",
    "        # Upload the video to Gemini\n",
    "        file_upload = genai_client.files.upload(file=str(test_video_path))\n",
    "        print(f\"File uploaded: {file_upload.name}\")\n",
    "        \n",
    "        # Wait for file to be processed (ACTIVE state)\n",
    "        max_retries = 10\n",
    "        retry_count = 0\n",
    "        while retry_count < max_retries:\n",
    "            # Check file status\n",
    "            file_info = genai_client.files.get(name=file_upload.name)\n",
    "            print(f\"File state: {file_info.state}\")\n",
    "            \n",
    "            if file_info.state == \"ACTIVE\":\n",
    "                print(f\"File is now active and ready for processing\")\n",
    "                break\n",
    "            \n",
    "            print(\"Waiting for file processing...\")\n",
    "            time.sleep(5)\n",
    "            retry_count += 1\n",
    "        \n",
    "        if retry_count == max_retries:\n",
    "            print(\"File processing timed out\")\n",
    "        else:\n",
    "            # Generate content with a simplified instruction\n",
    "            test_instruction = \"Please Follow the guidelines. Here is the video. RESPOND IN JSON FORMAT ONLY.\"\n",
    "            \n",
    "            response = genai_client.models.generate_content(\n",
    "                model=MODEL_ID,\n",
    "                config=GenerateContentConfig(\n",
    "        system_instruction=[engineer_location_model_instruction\n",
    "        ]\n",
    "    ),\n",
    "                contents=[\n",
    "                    {\"role\": \"user\", \"parts\": [\n",
    "                        {\"file_data\": {\"file_uri\": file_upload.uri, \"mime_type\": \"video/mp4\"}},\n",
    "                        {\"text\": test_instruction}\n",
    "                    ]}\n",
    "                ]\n",
    "            )\n",
    "            response_text = response.text\n",
    "            if \"```json\" in response_text:\n",
    "                response_text = response.text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            \n",
    "            print(\"Response received:\")\n",
    "            print(response_text)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in test script: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineer POV Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/video/TM000297/experiment_1/engineer/pov/chunk_1/chunk_1.mp4\n",
      "File uploaded: files/sr06z6tuf11\n",
      "File state: FileState.PROCESSING\n",
      "File files/sr06z6tuf11 is in FileState.PROCESSING state. Waiting...\n",
      "File state: FileState.ACTIVE\n",
      "File files/sr06z6tuf11 is now active and ready\n",
      "Error generating content: The read operation timed out\n",
      "Deleted file files/sr06z6tuf11 after error\n",
      "Processing data/video/TM000297/experiment_1/engineer/pov/chunk_2/chunk_2.mp4\n",
      "Error uploading file: The write operation timed out\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import time\n",
    "from google import genai\n",
    "import json\n",
    "from pathlib import Path\n",
    "from google.genai.types import GenerateContentConfig, HttpOptions\n",
    "\n",
    "# Initialize the client with extended timeout\n",
    "genai_client = genai.Client(\n",
    "    api_key=GEMINI_API_KEY,\n",
    "    http_options=HttpOptions(timeout=600)  # Extend timeout to 5 minutes\n",
    ")\n",
    "MODEL_ID = 'gemini-2.0-flash-exp'\n",
    "\n",
    "# Define the path to the engineer folder\n",
    "engineer_folder = Path(\"data/video/TM000297/experiment_1/engineer/pov\")\n",
    "\n",
    "# Loop over the chunks in the engineer folder\n",
    "for chunk_folder in engineer_folder.iterdir():\n",
    "    if chunk_folder.is_dir():\n",
    "        # Check if response already exists\n",
    "        response_file = chunk_folder / \"pov.json\"\n",
    "        if response_file.exists():\n",
    "            print(f\"Response already exists for {chunk_folder.name}, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        # Get the video file from the chunk folder\n",
    "        video_file = next(chunk_folder.glob(\"*.mp4\"), None)\n",
    "        if video_file:\n",
    "            print(f\"Processing {video_file}\")\n",
    "            \n",
    "            try:\n",
    "                # Upload the video to Gemini\n",
    "                try:\n",
    "                    file_upload = genai_client.files.upload(file=video_file)\n",
    "                    print(f\"File uploaded: {file_upload.name}\")\n",
    "                except Exception as upload_error:\n",
    "                    print(f\"Error uploading file: {upload_error}\")\n",
    "                    break\n",
    "                # Wait for file to be processed (ACTIVE state)\n",
    "                max_retries = 20  # Increase max retries\n",
    "                retry_count = 0\n",
    "                while retry_count < max_retries:\n",
    "                    # Check file status\n",
    "                    try:\n",
    "                        file_info = genai_client.files.get(name=file_upload.name)\n",
    "                        print(f\"File state: {file_info.state}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error fetching file info: {e}\")\n",
    "                        break\n",
    "                    if file_info.state == \"ACTIVE\":\n",
    "                        print(f\"File {file_upload.name} is now active and ready\")\n",
    "                        break\n",
    "                    \n",
    "                    print(f\"File {file_upload.name} is in {file_info.state} state. Waiting...\")\n",
    "                    time.sleep(10)  # Increase wait time between checks\n",
    "                    retry_count += 1\n",
    "                \n",
    "                if retry_count == max_retries:\n",
    "                    print(f\"File {file_upload.name} did not become active. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Generate content using the uploaded file and the instruction\n",
    "                try:\n",
    "                    response = genai_client.models.generate_content(\n",
    "                        model=MODEL_ID,\n",
    "                        config=GenerateContentConfig(\n",
    "                            system_instruction=[engineer_pov_model_instruction],\n",
    "                        ),\n",
    "                        contents=[\n",
    "                            {\"role\": \"user\", \"parts\": [\n",
    "                                {\"file_data\": {\"file_uri\": file_upload.uri, \"mime_type\": \"video/mp4\"}},\n",
    "                                {\"text\": \"Please Follow the guidelines. Here is the video. RESPOND IN JSON FORMAT ONLY.\"}\n",
    "                            ]}\n",
    "                        ]\n",
    "                    )\n",
    "                    \n",
    "                    # Clean and save the response\n",
    "                    response_text = response.text\n",
    "                    \n",
    "                    # Remove markdown code block syntax if present\n",
    "                    if \"```json\" in response_text:\n",
    "                        response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                    \n",
    "                    with open(response_file, \"w\") as f:\n",
    "                        f.write(response_text)\n",
    "                    print(f\"Saved response to {response_file}\")\n",
    "                    A\n",
    "                    # Add a cool-down period between API calls\n",
    "                    print(\"Cooling down for 30 seconds before next request...\")\n",
    "                    time.sleep(30)\n",
    "                    \n",
    "                except Exception as generate_error:\n",
    "                    print(f\"Error generating content: {generate_error}\")\n",
    "                    # Try to delete the file to free up resources\n",
    "                    try:\n",
    "                        genai_client.files.delete(name=file_upload.name)\n",
    "                        print(f\"Deleted file {file_upload.name} after error\")\n",
    "                    except:\n",
    "                        pass\n",
    "                    time.sleep(60)  # Wait longer before retrying another file\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video_file}: {e}\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import time\n",
    "from google import genai\n",
    "import json\n",
    "\n",
    "# Initialize the client\n",
    "genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "MODEL_ID = 'gemini-2.0-flash-exp'\n",
    "\n",
    "# Define the path to the engineer folder\n",
    "engineer_folder = Path(\"data/video/TM000297/experiment_1/engineer/location\")\n",
    "\n",
    "# Loop over the chunks in the engineer folder\n",
    "for chunk_folder in engineer_folder.iterdir():\n",
    "    if chunk_folder.is_dir():\n",
    "        # Get the video file from the chunk folder\n",
    "        video_file = next(chunk_folder.glob(\"*.mp4\"), None)\n",
    "        if video_file:\n",
    "            print(f\"Processing {video_file}\")\n",
    "            \n",
    "            try:\n",
    "                # Upload the video to Gemini\n",
    "                with open(video_file, \"rb\") as f:\n",
    "                    file_bytes = f.read()\n",
    "                \n",
    "                file_upload = genai_client.files.upload(file=str(video_file))\n",
    "                \n",
    "                # Wait for file to be processed (ACTIVE state)\n",
    "                max_retries = 10\n",
    "                retry_count = 0\n",
    "                while retry_count < max_retries:\n",
    "                    # Check file status\n",
    "                    file_info = genai_client.files.get(name=file_upload.name)\n",
    "                    if file_info.state == \"ACTIVE\":\n",
    "                        print(f\"File {file_upload.name} is now active and ready\")\n",
    "                        break\n",
    "                    \n",
    "                    print(f\"File {file_upload.name} is in {file_info.state} state. Waiting...\")\n",
    "                    time.sleep(5)  # Wait 5 seconds before checking again\n",
    "                    retry_count += 1\n",
    "                \n",
    "                if retry_count == max_retries:\n",
    "                    print(f\"File {file_upload.name} did not become active. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Generate content using the uploaded file and the instruction\n",
    "                response = genai_client.models.generate_content(\n",
    "                    model=MODEL_ID,\n",
    "                    config=GenerateContentConfig(\n",
    "                        system_instruction=[engineer_location_model_instruction]\n",
    "                    ),\n",
    "                    contents=[\n",
    "                        {\"role\": \"user\", \"parts\": [\n",
    "                            {\"file_data\": {\"file_uri\": file_upload.uri, \"mime_type\": \"video/mp4\"}},\n",
    "                            {\"text\": \"Please Follow the guidelines. Here is the video. RESPOND IN JSON FORMAT ONLY.\"}\n",
    "                        ]}\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                response_text = response.text\n",
    "                \n",
    "                # Remove markdown code block syntax if present\n",
    "                if \"```json\" in response_text:\n",
    "                    response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                \n",
    "                # Save the response to the same chunk folder as a JSON file\n",
    "                response_file = chunk_folder / \"location.json\"\n",
    "                with open(response_file, \"w\") as f:\n",
    "                    json.dump(response_text, f)\n",
    "                print(f\"Saved response to {response_file}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medic POV Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import time\n",
    "from google import genai\n",
    "import json\n",
    "\n",
    "# Initialize the client\n",
    "genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "MODEL_ID = 'gemini-2.0-flash-exp'\n",
    "\n",
    "# Define the path to the engineer folder\n",
    "medic_folder = Path(\"data/video/TM000297/experiment_1/medic/pov\")\n",
    "\n",
    "# Loop over the chunks in the engineer folder\n",
    "for chunk_folder in medic_folder.iterdir():\n",
    "    if chunk_folder.is_dir():\n",
    "        # Get the video file from the chunk folder\n",
    "        video_file = next(chunk_folder.glob(\"*.mp4\"), None)\n",
    "        if video_file:\n",
    "            print(f\"Processing {video_file}\")\n",
    "            \n",
    "            try:\n",
    "                # Upload the video to Gemini\n",
    "                with open(video_file, \"rb\") as f:\n",
    "                    file_bytes = f.read()\n",
    "                \n",
    "                file_upload = genai_client.files.upload(file=str(video_file))\n",
    "                \n",
    "                # Wait for file to be processed (ACTIVE state)\n",
    "                max_retries = 10\n",
    "                retry_count = 0\n",
    "                while retry_count < max_retries:\n",
    "                    # Check file status\n",
    "                    file_info = genai_client.files.get(name=file_upload.name)\n",
    "                    if file_info.state == \"ACTIVE\":\n",
    "                        print(f\"File {file_upload.name} is now active and ready\")\n",
    "                        break\n",
    "                    \n",
    "                    print(f\"File {file_upload.name} is in {file_info.state} state. Waiting...\")\n",
    "                    time.sleep(5)  # Wait 5 seconds before checking again\n",
    "                    retry_count += 1\n",
    "                \n",
    "                if retry_count == max_retries:\n",
    "                    print(f\"File {file_upload.name} did not become active. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Generate content using the uploaded file and the instruction\n",
    "                response = genai_client.models.generate_content(\n",
    "                    model=MODEL_ID,\n",
    "                    config=GenerateContentConfig(\n",
    "                        system_instruction=[medic_pov_model_instruction]\n",
    "                    ),\n",
    "                    contents=[\n",
    "                        {\"role\": \"user\", \"parts\": [\n",
    "                            {\"file_data\": {\"file_uri\": file_upload.uri, \"mime_type\": \"video/mp4\"}},\n",
    "                            {\"text\": \"Please Follow the guidelines. Here is the video. RESPOND IN JSON FORMAT ONLY.\"}\n",
    "                        ]}\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                response_text = response.text\n",
    "                \n",
    "                # Remove markdown code block syntax if present\n",
    "                if \"```json\" in response_text:\n",
    "                    response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                \n",
    "                # Save the response to the same chunk folder as a JSON file\n",
    "                response_file = chunk_folder / \"pov.json\"\n",
    "                with open(response_file, \"w\") as f:\n",
    "                    json.dump(response_text, f)\n",
    "                print(f\"Saved response to {response_file}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import time\n",
    "from google import genai\n",
    "import json\n",
    "\n",
    "# Initialize the client\n",
    "genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "MODEL_ID = 'gemini-2.0-flash-exp'\n",
    "\n",
    "# Define the path to the engineer folder\n",
    "medic_folder = Path(\"data/video/TM000297/experiment_1/medic/location\")\n",
    "\n",
    "# Loop over the chunks in the engineer folder\n",
    "for chunk_folder in medic_folder.iterdir():\n",
    "    if chunk_folder.is_dir():\n",
    "        # Get the video file from the chunk folder\n",
    "        video_file = next(chunk_folder.glob(\"*.mp4\"), None)\n",
    "        if video_file:\n",
    "            print(f\"Processing {video_file}\")\n",
    "            \n",
    "            try:\n",
    "                # Upload the video to Gemini\n",
    "                with open(video_file, \"rb\") as f:\n",
    "                    file_bytes = f.read()\n",
    "                \n",
    "                file_upload = genai_client.files.upload(file=str(video_file))\n",
    "                \n",
    "                # Wait for file to be processed (ACTIVE state)\n",
    "                max_retries = 10\n",
    "                retry_count = 0\n",
    "                while retry_count < max_retries:\n",
    "                    # Check file status\n",
    "                    file_info = genai_client.files.get(name=file_upload.name)\n",
    "                    if file_info.state == \"ACTIVE\":\n",
    "                        print(f\"File {file_upload.name} is now active and ready\")\n",
    "                        break\n",
    "                    \n",
    "                    print(f\"File {file_upload.name} is in {file_info.state} state. Waiting...\")\n",
    "                    time.sleep(5)  # Wait 5 seconds before checking again\n",
    "                    retry_count += 1\n",
    "                \n",
    "                if retry_count == max_retries:\n",
    "                    print(f\"File {file_upload.name} did not become active. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Generate content using the uploaded file and the instruction\n",
    "                response = genai_client.models.generate_content(\n",
    "                    model=MODEL_ID,\n",
    "                    config=GenerateContentConfig(\n",
    "                        system_instruction=[medic_location_model_instruction]\n",
    "                    ),\n",
    "                    contents=[\n",
    "                        {\"role\": \"user\", \"parts\": [\n",
    "                            {\"file_data\": {\"file_uri\": file_upload.uri, \"mime_type\": \"video/mp4\"}},\n",
    "                            {\"text\": \"Please Follow the guidelines. Here is the video. RESPOND IN JSON FORMAT ONLY.\"}\n",
    "                        ]}\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                response_text = response.text\n",
    "                \n",
    "                # Remove markdown code block syntax if present\n",
    "                if \"```json\" in response_text:\n",
    "                    response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                \n",
    "                # Save the response to the same chunk folder as a JSON file\n",
    "                response_file = chunk_folder / \"location.json\"\n",
    "                with open(response_file, \"w\") as f:\n",
    "                    json.dump(response_text, f)\n",
    "                print(f\"Saved response to {response_file}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transporter POV Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import time\n",
    "from google import genai\n",
    "import json\n",
    "\n",
    "# Initialize the client\n",
    "genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "MODEL_ID = 'gemini-2.0-flash-exp'\n",
    "\n",
    "# Define the path to the engineer folder\n",
    "transporter_folder = Path(\"data/video/TM000297/experiment_1/transporter/pov\")\n",
    "\n",
    "# Loop over the chunks in the engineer folder\n",
    "for chunk_folder in transporter_folder.iterdir():\n",
    "    if chunk_folder.is_dir():\n",
    "        # Get the video file from the chunk folder\n",
    "        video_file = next(chunk_folder.glob(\"*.mp4\"), None)\n",
    "        if video_file:\n",
    "            print(f\"Processing {video_file}\")\n",
    "            \n",
    "            try:\n",
    "                # Upload the video to Gemini\n",
    "                with open(video_file, \"rb\") as f:\n",
    "                    file_bytes = f.read()\n",
    "                \n",
    "                file_upload = genai_client.files.upload(file=str(video_file))\n",
    "                \n",
    "                # Wait for file to be processed (ACTIVE state)\n",
    "                max_retries = 10\n",
    "                retry_count = 0\n",
    "                while retry_count < max_retries:\n",
    "                    # Check file status\n",
    "                    file_info = genai_client.files.get(name=file_upload.name)\n",
    "                    if file_info.state == \"ACTIVE\":\n",
    "                        print(f\"File {file_upload.name} is now active and ready\")\n",
    "                        break\n",
    "                    \n",
    "                    print(f\"File {file_upload.name} is in {file_info.state} state. Waiting...\")\n",
    "                    time.sleep(5)  # Wait 5 seconds before checking again\n",
    "                    retry_count += 1\n",
    "                \n",
    "                if retry_count == max_retries:\n",
    "                    print(f\"File {file_upload.name} did not become active. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Generate content using the uploaded file and the instruction\n",
    "                response = genai_client.models.generate_content(\n",
    "                    model=MODEL_ID,\n",
    "                    config=GenerateContentConfig(\n",
    "                        system_instruction=[transporter_pov_model_instruction]\n",
    "                    ),\n",
    "                    contents=[\n",
    "                        {\"role\": \"user\", \"parts\": [\n",
    "                            {\"file_data\": {\"file_uri\": file_upload.uri, \"mime_type\": \"video/mp4\"}},\n",
    "                            {\"text\": \"Please Follow the guidelines. Here is the video. RESPOND IN JSON FORMAT ONLY.\"}\n",
    "                        ]}\n",
    "                    ]\n",
    "                )\n",
    "                response_text = response.text\n",
    "                \n",
    "                # Remove markdown code block syntax if present\n",
    "                if \"```json\" in response_text:\n",
    "                    response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                # Save the response to the same chunk folder as a JSON file\n",
    "                response_file = chunk_folder / \"pov.json\"\n",
    "                with open(response_file, \"w\") as f:\n",
    "                    json.dump(response_text, f)\n",
    "                print(f\"Saved response to {response_file}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import time\n",
    "from google import genai\n",
    "import json\n",
    "\n",
    "# Initialize the client\n",
    "genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "MODEL_ID = 'gemini-2.0-flash-exp'\n",
    "\n",
    "# Define the path to the engineer folder\n",
    "transporter_folder = Path(\"data/video/TM000297/experiment_1/transporter/location\")\n",
    "\n",
    "# Loop over the chunks in the engineer folder\n",
    "for chunk_folder in transporter_folder.iterdir():\n",
    "    if chunk_folder.is_dir():\n",
    "        # Get the video file from the chunk folder\n",
    "        video_file = next(chunk_folder.glob(\"*.mp4\"), None)\n",
    "        if video_file:\n",
    "            print(f\"Processing {video_file}\")\n",
    "            \n",
    "            try:\n",
    "                # Upload the video to Gemini\n",
    "                with open(video_file, \"rb\") as f:\n",
    "                    file_bytes = f.read()\n",
    "                \n",
    "                file_upload = genai_client.files.upload(file=str(video_file))\n",
    "                \n",
    "                # Wait for file to be processed (ACTIVE state)\n",
    "                max_retries = 10\n",
    "                retry_count = 0\n",
    "                while retry_count < max_retries:\n",
    "                    # Check file status\n",
    "                    file_info = genai_client.files.get(name=file_upload.name)\n",
    "                    if file_info.state == \"ACTIVE\":\n",
    "                        print(f\"File {file_upload.name} is now active and ready\")\n",
    "                        break\n",
    "                    \n",
    "                    print(f\"File {file_upload.name} is in {file_info.state} state. Waiting...\")\n",
    "                    time.sleep(5)  # Wait 5 seconds before checking again\n",
    "                    retry_count += 1\n",
    "                \n",
    "                if retry_count == max_retries:\n",
    "                    print(f\"File {file_upload.name} did not become active. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Generate content using the uploaded file and the instruction\n",
    "                response = genai_client.models.generate_content(\n",
    "                    model=MODEL_ID,\n",
    "                    config=GenerateContentConfig(\n",
    "                        system_instruction=[transporter_location_model_instruction]\n",
    "                    ),\n",
    "                    contents=[\n",
    "                        {\"role\": \"user\", \"parts\": [\n",
    "                            {\"file_data\": {\"file_uri\": file_upload.uri, \"mime_type\": \"video/mp4\"}},\n",
    "                            {\"text\": \"Please Follow the guidelines. Here is the video. RESPOND IN JSON FORMAT ONLY.\"}\n",
    "                        ]}\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                response_text = response.text\n",
    "                \n",
    "                # Remove markdown code block syntax if present\n",
    "                if \"```json\" in response_text:\n",
    "                    response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                \n",
    "                # Save the response to the same chunk folder as a JSON file\n",
    "                response_file = chunk_folder / \"location.json\"\n",
    "                with open(response_file, \"w\") as f:\n",
    "                    json.dump(response_text, f)\n",
    "                print(f\"Saved response to {response_file}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract JSON action_states to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_action_states = pd.DataFrame([\"timestamp\",\"engineer_action_state\",\"medic_action_state\",\"transporter_action_state\"])\n",
    "# merge df_action_states to df dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion LLM Text Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Objective\n",
    "\n",
    "Use LLM to analyze each agent's communication, location and state to form one [agent]_action_state \n",
    "\n",
    "**1. Map State**-\n",
    "\n",
    "Location of the agent in the map -> Room Name\n",
    "\n",
    "**2. Agent Action**-\n",
    "\n",
    "1. chat\n",
    "2. door\n",
    "3. ItemDrop\n",
    "4. ItemEquipped\n",
    "5. ItemPickup\n",
    "6. ItemUsed\n",
    "7. Lever\n",
    "8. PlayerJumped\n",
    "9. PlayerSprinting\n",
    "10. Scoreboard\n",
    "11. Triage\n",
    "12. RoleSelected\n",
    "13. ProximityBlockInteraction\n",
    "14. PlayerFrozenStateChange\n",
    "15. ToolUsed\n",
    "16. CompetencyTask\n",
    "17. TrainingTask\n",
    "18. ToolDepleted\n",
    "19. MarkerPlaced\n",
    "20. MarkerRemoved\n",
    "21. RubbleCollapse\n",
    "22. VictimEvacuated\n",
    "23. VictimPickedUp\n",
    "24. VictimPlaced\n",
    "25. RubbleDestroyed\n",
    "26. Signal\n",
    "27. Pause\n",
    "28. MissionState\n",
    "29. Perturbation\n",
    "30. PlanningStage\n",
    "31. PerturbationRubbleLocations\n",
    "32. location\n",
    "33. proximity\n",
    "34. dyad\n",
    "35. VictimsExpired\n",
    "36. PuzzleTextSummary\n",
    "37. dialogue_event\n",
    "38. TrialState\n",
    "\n",
    "**3. Agent Message**-\n",
    "\n",
    "Raw message extracted from transcript.csv\n",
    "\n",
    "### Prompt for AI Modal \n",
    "\n",
    "You are \n",
    "\n",
    "### Response Type\n",
    "\n",
    "```json\n",
    "{\n",
    "    agent: \"engineer | transporter | medic | victim\", [agent]_action_state \" [Agent] was likely doing this at this location \" \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass each row to LLM and retreive JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert JSON to a single dataframe of csv -> [agent]_action_state and append it to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score LLM Text Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Objective\n",
    "\n",
    "Use LLM to analyze agent's advice and team's communication and collaboration to form team_score and asi_advice score\n",
    "\n",
    "| timestamp | asi_reason | asi_action | transporter_message | engineer_message | medic_message | transporter_action_state | engineer_action_state | medic_action_state | victim_location | \n",
    "| --------- | --------- | --------- | ------------------ | --------------- | ------------ | --------------- | --------------- | ------------ | --------------- |\n",
    "|           |           |           |                    |                 |              |                 |                 |              |                 |\n",
    "\n",
    "### Prompt for AI Modal \n",
    "\n",
    "You are \n",
    "\n",
    "### Response Type\n",
    "\n",
    "```json\n",
    "{\n",
    "    asi_advice_score: \"number %\", team_score : \"number %\" \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass each row to LLM and retreive JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert JSON to a single dataframe of csv -> team_score and asi_advice score and append it to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
