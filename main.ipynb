{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Modal Data Analysis Workflow\n",
    "\n",
    "**ASIST Study 3 Dataset**\n",
    "\n",
    "#### **Team 000286 Pre-Result Analysis**\n",
    "\n",
    "Engineer exibited poor skill during the hands on training. It took him a very long time to complete the individual training which resulted in the mission timer running out during the team training section. Once the timer expired, the hands-on training trial was restarted and participants again completed the individual training. Engineer's second attempt still took over 5 minutes to complete individual training. The competency test was then started at 13m remaining on the timer, the engineer took a full 5 minutes to complete the competency test. Experiment team decided that engineer should be allowed to proceed to avoid rescheduling dispite the evident lack of minecraft skill.\n",
    "\n",
    "## Objective\n",
    "\n",
    "Analyze team performance data across four modalities:\n",
    "\n",
    "1. JSON behavior logs\n",
    "2. Video recordings\n",
    "3. Chat transcripts\n",
    "\n",
    "Identify correlations between AI interventions and team outcomes.\n",
    "\n",
    "## Note\n",
    "\n",
    "All datasets were taken from official CHART ASIST Study 3 Dataset available at ASU official repository.\n",
    "\n",
    "#### Subset used :\n",
    "\n",
    "| Team ID | ASI ID        | trial   | intervention_recipent     |\n",
    "| ------- | ------------- | ------- | ------------------------- |\n",
    "| 000286  | ASI-CMURI-TA1 | T000829 | E001211, E001215, E001155 |\n",
    "\n",
    "\n",
    "\n",
    "**AI Agent Action signals** -\n",
    "\n",
    "1. RemindTransporterBeep\n",
    "2. InformAboutTriagedVictim\n",
    "3. RemindMedicToInformAboutTriagedVicti\n",
    "4. TriageCriticalVictim\n",
    "5. EvacuateCriticalVictim\n",
    "6. EncouragePlayerProximityToMedicIHMCDyad\n",
    "7. RemindChangeMarke\n",
    "8. RemindRubblePerturbatio\n",
    "9. EvacuationZoneDistanc\n",
    "10. TeamSawVictimMarke\n",
    "11. TimeElapse\n",
    "12. StartEvacuatio\n",
    "\n",
    "**Agents location**-\n",
    "\n",
    "1. Location of the agent in the map -> Room Name\n",
    "\n",
    "**Agent Action**-\n",
    "\n",
    "1. Transporting victims\n",
    "2. Performing their role task including stabilizing victims\n",
    "3. wakening up critical victims\n",
    "4. placing marking block-> Regular, A, B, C\n",
    "5. placing marking block for threat rooms\n",
    "6. removing rubbles\n",
    "7. detecting victims\n",
    "\n",
    "## Manual Dataframe\n",
    "\n",
    "Timestamp, AI Message, AI Action Class, Transporter Message, Engineer Message, Medic Message is extracted from transcript.csv\n",
    "\n",
    "We use Multimodal LLM analysis to analyze video data to give states and locations of agents + victims throughout the experiment\n",
    "\n",
    "\n",
    "| Time Stamp (Transcript) | Asi Message (Transcript) | Asi Action Class (Transcript) | Transporter Message (Transcript) | Engineer Message (Transcript) | Medic Message (Transcript) |\n",
    "| ----------------------- | ------------------------ | ----------------------------- | ------------------------------- | ----------------------------- | -------------------------- |\n",
    "| 11:23:01                | N/A                      | N/A                           | N/A                             | N/A                           | N/A                        |\n",
    "\n",
    "## llmv1 Dataframe\n",
    "\n",
    "States tells us what the agent is doing\n",
    "Locations tells use where the agent is located in the map\n",
    "\n",
    "States and locations are fused together using LLM analysis to form one action_state column signifying their role in a situation\n",
    "\n",
    "| timestamp (Transcript) | asi_reason (Transcript) | asi_action (Transcript) | transporter_message (Transcript) | engineer_message (Transcript) | medic_message (Transcript) | transporter_action_state (LLM) | engineer_action_state (LLM) | medic_action_state (LLM) | victim_location (LLM) | \n",
    "| --------- | --------- | --------- | ------------------ | --------------- | ------------ | --------------- | --------------- | ------------ | --------------- |\n",
    "|           |           |           |                    |                 |              |                 |                 |              |                 |\n",
    "\n",
    "\n",
    "We then utilize another LLM to finally provide ASI Advice score and team score for their actions and LLM's reasoning behiind that\n",
    "\n",
    "## llmv2 Dataframe\n",
    "| timestamp (Transcript) | asi_reason (Transcript) | asi_action (Transcript) | transporter_message (Transcript) | engineer_message (Transcript) | medic_message (Transcript) | transporter_action_state (LLM) | engineer_action_state (LLM) | medic_action_state (LLM) | victim_location (LLM) | team_score (LLM) | asi_advice_score (LLM) | team_score_reason (LLM) | asi_advice_score_reason (LLM)\n",
    "| --------- | --------- | --------- | ------------------ | --------------- | ------------ | --------------- | ---------- | --------------- | --------------- |--------------- |--------------- | --------------- | --------------- |\n",
    "|     22:03      |   You guys should do [asi_action_class] because...        | 1. RemindTransporterBeep <br/>2. InformAboutTriagedVictim <br/>3. RemindMedicToInformAboutTriagedVicti <br/>4. TriageCriticalVictim <br/>5. EvacuateCriticalVictim <br/>6.EncouragePlayerProximityToMedicIHMCDyad <br/>7. RemindChangeMarke <br/>8. RemindRubblePerturbatio <br/>9. EvacuationZoneDistanc <br/>10. TeamSawVictimMarke <br/>11. TimeElapse <br/>12. StartEvacuatio|     I'm coming for you medic               |     This is more important               |     I can't help you!               |     Carrying a victim from b4 to B2 room               |     Clearing rubbles in threat room for medic  at a9 room          |     waking up critical victim at g5 room        |    next to medic, far from engineer, close to transporter            |  40%          |     75%           | team was inconsistent with their tasks, especially... | asi's advice is particularly useful because... |\n",
    "\n",
    "\n",
    "## AI Instruct Modal\n",
    "\n",
    "We finetune pretrained LLM on our data for understanding minecraft test bed for asist thoroughly and deeply. Then we utilize it to perform-\n",
    "\n",
    "1. **Multimodal DataAnalysis of Video Data** \n",
    "\n",
    "To give information about agent locations and their actions\n",
    "\n",
    "2. **Text Fusion Data Analysis**\n",
    "\n",
    "To fuse meanings and relationships between agent communication, their location and state in given situations to a single column\n",
    "\n",
    "3. **Scoring Analysis**\n",
    "\n",
    "To score humans and ASI's advice on team work communication and collaboration data   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "# import openai\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "# import torch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch GEMINI_API_KEY\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. JSON Logs Processing\n",
    "#### Objective\n",
    "Extract structured data from nested JSON logs containing:\n",
    "- Team actions\n",
    "- AI intervention timestamps\n",
    "- Mission outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def parse_json_logs(input_path: Path, output_path: Path) -> pd.DataFrame:\n",
    "#     \"\"\"Flatten nested JSON logs into structured format\"\"\"\n",
    "#     with open(input_path, 'r') as f:\n",
    "#         data = [json.loads(line) for line in f]\n",
    "    \n",
    "#     df = pd.json_normalize(data, sep='_')\n",
    "#     df.to_csv(output_path, index=False)\n",
    "#     return df\n",
    "\n",
    "# # Process all trial messages\n",
    "# input_files = [\n",
    "#     Path(\"data/json_logs/HSRData_TrialMessages_Trial-T000603_...\"),\n",
    "#     Path(\"data/json_logs/HSRData_TrialMessages_Trial-T000639_...\"),\n",
    "#     Path(\"data/json_logs/HSRData_TrialMessages_Trial-T000671_...\")\n",
    "# ]\n",
    "\n",
    "# output_dir = Path(\"data/processed/json_parsed/\")\n",
    "# output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# for file in input_files:\n",
    "#     output_file = output_dir / f\"{file.stem}_parsed.csv\"\n",
    "#     df = parse_json_logs(file, output_file)\n",
    "#     print(f\"Processed {len(df)} records from {file.name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective \n",
    "\n",
    "Finetune the pretrained instruct model on testbed refined high quality data and information about agents, environment, locations. \n",
    "\n",
    "\n",
    "1. Transporting victims\n",
    "2. Performing their role task including stabilizing victims\n",
    "3. wakening up critical victims\n",
    "4. placing marking block-> Regular, A, B, C\n",
    "5. placing marking block for threat rooms\n",
    "6. removing rubbles\n",
    "7. detecting victims\n",
    "\n",
    "![image.png](chart_study3_guide/blocks.png)\n",
    "\n",
    "\n",
    "![image.png](chart_study3_guide/map.png)\n",
    "\n",
    "\n",
    "\n",
    "[ Maybe : Train model to understand video data as well ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineer Instruct POV Model\n",
    "\n",
    "Finetune the pretrained instruct model on testbed refined high quality data and information about agents actions in minecraft video. \n",
    "\n",
    "#### Possible Actions\n",
    "\n",
    "1. Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \n",
    "2. Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\n",
    "3. Destroying rubles for making way for rescue teammates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " You are a professional Minecraft Agent Location tracker. You only have to track where the agent is on the map view. Follow this guideline thoroughly to log the location details every 3 seconds of the video.\n",
      "\n",
      "1. The Location Map Video:\n",
      " - The video shows a map view with a blue dot representing the Engineer agent. Your job is to track this blue dot and report its position. Key points:\n",
      "    a) Location of the agent throughout the map across various zones\n",
      "    b) Movement between rooms or zones\n",
      "    c) Time spent in specific locations\n",
      "\n",
      "2. Map Details:\n",
      " - The map is divided into several zones labeled as N Zone A, N Zone B, N Zone C, S Zone A, S Zone B, and S Zone C\n",
      " - Each zone contains subzones labeled with alphanumeric identifiers (e.g., A1, B2, C3, etc.)\n",
      " - Key landmarks:\n",
      "    - Yellow markers indicate victims or threats\n",
      "    - Red markers indicate critical victims or rubble\n",
      "    - Blue markers indicate regular victims or help requests\n",
      "\n",
      "3. Logging Instructions:\n",
      " - Log the blue dot's position every 3 seconds TILL THE VERY END OF THE VIDEO in JSON format\n",
      " - Note any zone transitions or prolonged stays in one location\n",
      "\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Engineer POV model instruction (focusing only on in-game actions)\n",
    "engineer_pov_model_instruction = \"\"\"You are a professional Minecraft Agent Activity Logger. You only have to log what the agent is doing in their first-person view. DO NOT listen to what they're saying. Follow this guideline thoroughly to log any of these important details which are happening in the video every 3 seconds of the video. \n",
    "\n",
    "1. The Minecraft Agent POV Video:\n",
    " - The video shows what the Engineer agent is doing in first-person view. The Engineer's job is to work together with a medic and transporter to save victims in a Minecraft rescue simulation. Key events to document:\n",
    "    a) Placing Avatar Yellow Marker Block for notifying there's a victim nearby\n",
    "    b) Placing Blank Yellow Marker Block for notifying there's a threat room nearby\n",
    "    c) Placing Avatar Red Marker Block for notifying there's a critical victim nearby\n",
    "    d) Placing Avatar Blue Marker Block for notifying there's a regular victim nearby\n",
    "    e) Placing Blank Red Marker Block for notifying there's rubble nearby\n",
    "    f) Placing Blank Blue Marker Block for notifying there's a help request nearby\n",
    "    g) Destroying rubbles for making way for rescue teammates\n",
    "    h) Interacting with any blocks or items\n",
    "    i) Moving through hallways or rooms\n",
    "    j) Encountering other players (the Engineer wears blue skin, medic wears red, and the transporter wears green skin)\n",
    "\n",
    "2. Logging Instructions:\n",
    " - Log the agent's activity every 3 seconds TILL THE VERY END OF THE VIDEO in JSON format\n",
    " - If no key event occurs, log that \"nothing significant is happening\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Engineer Location model instruction (focusing only on map location)\n",
    "engineer_location_model_instruction = \"\"\"You are a professional Minecraft Agent Location tracker. You only have to track where the agent is on the map view. Follow this guideline thoroughly to log the location details every 3 seconds of the video.\n",
    "\n",
    "1. The Location Map Video:\n",
    " - The video shows a map view with a blue dot representing the Engineer agent. Your job is to track this blue dot and report its position. Key points:\n",
    "    a) Location of the agent throughout the map across various zones\n",
    "    b) Movement between rooms or zones\n",
    "    c) Time spent in specific locations\n",
    "\n",
    "2. Map Details:\n",
    " - The map is divided into several zones labeled as N Zone A, N Zone B, N Zone C, S Zone A, S Zone B, and S Zone C\n",
    " - Each zone contains subzones labeled with alphanumeric identifiers (e.g., A1, B2, C3, etc.)\n",
    " - Key landmarks:\n",
    "    - Yellow markers indicate victims or threats\n",
    "    - Red markers indicate critical victims or rubble\n",
    "    - Blue markers indicate regular victims or help requests\n",
    "\n",
    "3. Logging Instructions:\n",
    " - Log the blue dot's position every 3 seconds TILL THE VERY END OF THE VIDEO in JSON format\n",
    " - Note any zone transitions or prolonged stays in one location\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(\"\\n\", engineer_location_model_instruction, \"\\n\", )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medic Instruct POV \n",
    "\n",
    "Finetune the pretrained instruct model on testbed refined high quality data and information about agents actions in minecraft video. \n",
    "\n",
    "1. Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \n",
    "2. Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\n",
    "3. Stabilizing avatar victim blocks turning into safe blocks.\n",
    "4. Stabilizing avatar victim blocks turning into X blocks notifying victim is dead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a professional Minecraft Agent Location tracker. You only have to track where the agent is on the map view. Follow this guideline thoroughly to log the location details every 3 seconds of the video.\n",
      "\n",
      "1. The Location Map Video:\n",
      " - The video shows a map view with a red dot representing the Medic agent. Your job is to track this red dot and report its position. Key points:\n",
      "    a) Location of the agent throughout the map across various zones\n",
      "    b) Movement between rooms or zones\n",
      "    c) Time spent in specific locations\n",
      "\n",
      "2. Map Details:\n",
      " - The map is divided into several zones labeled as N Zone A, N Zone B, N Zone C, S Zone A, S Zone B, and S Zone C\n",
      " - Each zone contains subzones labeled with alphanumeric identifiers (e.g., A1, B2, C3, etc.)\n",
      " - Key landmarks:\n",
      "    - Yellow markers indicate victims or threats\n",
      "    - Red markers indicate critical victims or rubble\n",
      "    - Blue markers indicate regular victims or help requests\n",
      "\n",
      "3. Logging Instructions:\n",
      " - Log the red dot's position every 3 seconds in JSON format\n",
      " - Note any zone transitions or prolonged stays in one location\n",
      "\n"
     ]
    }
   ],
   "source": [
    "medic_pov_model_instruction = \"\"\"You are a professional Minecraft Medic Agent Activity analyzer. You only have to log what the agent is doing in their first-person view. DO NOT listen to what they're saying. Follow this guideline thoroughly to log any of these important details which are happening in the video every 3 seconds of the video.\n",
    "\n",
    "1. The Minecraft Agent POV Video:\n",
    " - The video shows what the Medic agent is doing in first-person view. The Medic's job is to work together with an engineer and transporter to save victims in a Minecraft rescue simulation. Key events to document:\n",
    "    a) Placing Avatar Yellow Marker Block for notifying there's a victim nearby\n",
    "    b) Placing Blank Yellow Marker Block for notifying there's a threat room nearby\n",
    "    c) Placing Avatar Red Marker Block for notifying there's a critical victim nearby\n",
    "    d) Placing Avatar Blue Marker Block for notifying there's a regular victim nearby\n",
    "    e) Stabilizing avatar victim blocks turning into safe blocks\n",
    "    f) Stabilizing avatar victim blocks turning into X blocks notifying victim is dead\n",
    "    g) Moving through hallways or rooms\n",
    "    h) Encountering other players (the Medic wears red skin, engineer wears blue, and the transporter wears green skin)\n",
    "\n",
    "2. Logging Instructions:\n",
    " - Log the agent's activity every 3 seconds TILL THE VERY END OF THE VIDEO\n",
    " - If no key event occurs, log that \"nothing significant is happening\"\n",
    "\"\"\"\n",
    "\n",
    "# New model instruction for location analysis\n",
    "medic_location_model_instruction = \"\"\"You are a professional Minecraft Agent Location tracker. You only have to track where the agent is on the map view. Follow this guideline thoroughly to log the location details every 3 seconds of the video.\n",
    "\n",
    "1. The Location Map Video:\n",
    " - The video shows a map view with a red dot representing the Medic agent. Your job is to track this red dot and report its position. Key points:\n",
    "    a) Location of the agent throughout the map across various zones\n",
    "    b) Movement between rooms or zones\n",
    "    c) Time spent in specific locations\n",
    "\n",
    "2. Map Details:\n",
    " - The map is divided into several zones labeled as N Zone A, N Zone B, N Zone C, S Zone A, S Zone B, and S Zone C\n",
    " - Each zone contains subzones labeled with alphanumeric identifiers (e.g., A1, B2, C3, etc.)\n",
    " - Key landmarks:\n",
    "    - Yellow markers indicate victims or threats\n",
    "    - Red markers indicate critical victims or rubble\n",
    "    - Blue markers indicate regular victims or help requests\n",
    "\n",
    "3. Logging Instructions:\n",
    " - Log the red dot's position every 3 seconds in JSON format\n",
    " - Note any zone transitions or prolonged stays in one location\n",
    "\"\"\"\n",
    "print(medic_location_model_instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transporter Instruct POV Model\n",
    "\n",
    "\n",
    "Finetune the pretrained instruct model on testbed refined high quality data and information about agents actions in minecraft video. \n",
    "\n",
    "\n",
    "1. Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \n",
    "2. Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\n",
    "3. Transporting victims from location to location.\n",
    "4. Standing on wifi signal block to detect victims nearby.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a professional Minecraft Transporter Agent Activity analyzer. You only have to log what the agent is doing in their first-person view. DO NOT listen to what they're saying. Follow this guideline thoroughly to log any of these important details which are happening in the video every 3 seconds of the video.\n",
      "\n",
      "1. The Minecraft Agent POV Video:\n",
      " - The video shows what the Transporter agent is doing in first-person view. The Transporter's job is to work together with an engineer and medic to save victims in a Minecraft rescue simulation. Key events to document:\n",
      "    a) Placing Avatar Yellow Marker Block for notifying there's a victim nearby\n",
      "    b) Placing Blank Yellow Marker Block for notifying there's a threat room nearby\n",
      "    c) Placing Avatar Red Marker Block for notifying there's a critical victim nearby\n",
      "    d) Placing Avatar Blue Marker Block for notifying there's a regular victim nearby\n",
      "    e) Placing Blank Red Marker Block for notifying there's rubble nearby\n",
      "    f) Placing Blank Blue Marker Block for notifying there's a help request nearby\n",
      "    g) Transporting victims from location to location\n",
      "    h) Standing on wifi signal block to detect victims nearby\n",
      "    i) Moving through hallways or rooms\n",
      "    j) Encountering other players (the Transporter wears green skin, engineer wears blue, and the medic wears red skin)\n",
      "\n",
      "2. Logging Instructions:\n",
      " - Log the agent's activity every 3 seconds in JSON format\n",
      " - If no key event occurs, log that \"nothing significant is happening\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transporter_pov_model_instruction = \"\"\"You are a professional Minecraft Transporter Agent Activity analyzer. You only have to log what the agent is doing in their first-person view. DO NOT listen to what they're saying. Follow this guideline thoroughly to log any of these important details which are happening in the video every 3 seconds of the video.\n",
    "\n",
    "1. The Minecraft Agent POV Video:\n",
    " - The video shows what the Transporter agent is doing in first-person view. The Transporter's job is to work together with an engineer and medic to save victims in a Minecraft rescue simulation. Key events to document:\n",
    "    a) Placing Avatar Yellow Marker Block for notifying there's a victim nearby\n",
    "    b) Placing Blank Yellow Marker Block for notifying there's a threat room nearby\n",
    "    c) Placing Avatar Red Marker Block for notifying there's a critical victim nearby\n",
    "    d) Placing Avatar Blue Marker Block for notifying there's a regular victim nearby\n",
    "    e) Placing Blank Red Marker Block for notifying there's rubble nearby\n",
    "    f) Placing Blank Blue Marker Block for notifying there's a help request nearby\n",
    "    g) Transporting victims from location to location\n",
    "    h) Standing on wifi signal block to detect victims nearby\n",
    "    i) Moving through hallways or rooms\n",
    "    j) Encountering other players (the Transporter wears green skin, engineer wears blue, and the medic wears red skin)\n",
    "\n",
    "2. Logging Instructions:\n",
    " - Log the agent's activity every 3 seconds in JSON format\n",
    " - If no key event occurs, log that \"nothing significant is happening\"\n",
    "\"\"\"\n",
    "\n",
    "# New model instruction for location analysis\n",
    "transporter_location_model_instruction = \"\"\"You are a professional Minecraft Agent Location tracker. You only have to track where the agent is on the map view. Follow this guideline thoroughly to log the location details every 3 seconds of the video.\n",
    "\n",
    "1. The Location Map Video:\n",
    " - The video shows a map view with a green dot representing the Transporter agent. Your job is to track this green dot and report its position. Key points:\n",
    "    a) Location of the agent throughout the map across various zones\n",
    "    b) Movement between rooms or zones\n",
    "    c) Time spent in specific locations\n",
    "\n",
    "2. Map Details:\n",
    " - The map is divided into several zones labeled as N Zone A, N Zone B, N Zone C, S Zone A, S Zone B, and S Zone C\n",
    " - Each zone contains subzones labeled with alphanumeric identifiers (e.g., A1, B2, C3, etc.)\n",
    " - Key landmarks:\n",
    "    - Yellow markers indicate victims or threats\n",
    "    - Red markers indicate critical victims or rubble\n",
    "    - Blue markers indicate regular victims or help requests\n",
    "\n",
    "3. Logging Instructions:\n",
    " - Log the green dot's position every 3 seconds in JSON format\n",
    " - Note any zone transitions or prolonged stays in one location\n",
    "\n",
    "\"\"\"\n",
    "print(transporter_pov_model_instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player's Action State Fusor Model\n",
    "\n",
    "\n",
    "Fuses player actions and their location in maps to form a rich action state data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a professional context summarizer. Your job is to analyze a data having two properties which is action and state. You have to summarize the data into a single sentence. The data is about a minecraft test bed rescue simulation where three agents named Engineer, Medic and Transporter work and communicate with each other to rescue victims from threat rooms. Here is some information about the agents :\\n1. Engineer : Engineer agent wears blue skin while medic wears red and transporter wears green skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there\\'s a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there\\'s a threat room nearby for others to be aware.\\nc) Destroying rubles for making way for rescue teammates.\\n2. Transporter :  Transporter agent wears green skin while engineer wears blue and medic wears red skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there\\'s a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there\\'s a threat room nearby for others to be aware.\\nc) Transporting victims from location to location.\\nd) Standing on wifi signal block to detect victims nearby.\\n3. Medic : Medic agent wears red skin while engineer wears blue and transporter wears green skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there\\'s a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there\\'s a threat room nearby for others to be aware.\\nc) Stabilizing avatar victim blocks turning into safe blocks\\nd) Stabilizing avatar victim blocks turning into X blocks notifying victim is dead. \\nHere are all important things to consider - \\n- 1. Action : \\n - The action is what the agent might be doing or did in their task during the environment mission. \\n- 2. Communication : \\n - The communication transmitted from agent in the video shared with either of medic, transporter or engineer. \\n It\\'s not neccessary that every second there will be a key event so you can just say that nothing is happening in the video. Example JSON Response -\\n{timestamp: \"00:03\", \"action_state\":\"Engineer went into A2 Zone to help medic and destroyed rubble\"},{timestamp: \"00:09\", \"action_state\":\"Medic was just communicating but did nothing from its side\"}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_state_fusor_model_instruction = \"\"\"You are a professional context summarizer. Your job is to analyze a data having two properties which is action and state. You have to summarize the data into a single sentence. The data is about a minecraft test bed rescue simulation where three agents named Engineer, Medic and Transporter work and communicate with each other to rescue victims from threat rooms. Here is some information about the agents :\\n1. Engineer : Engineer agent wears blue skin while medic wears red and transporter wears green skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\\nc) Destroying rubles for making way for rescue teammates.\\n2. Transporter :  Transporter agent wears green skin while engineer wears blue and medic wears red skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\\nc) Transporting victims from location to location.\\nd) Standing on wifi signal block to detect victims nearby.\\n3. Medic : Medic agent wears red skin while engineer wears blue and transporter wears green skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\\nc) Stabilizing avatar victim blocks turning into safe blocks\\nd) Stabilizing avatar victim blocks turning into X blocks notifying victim is dead. \\nHere are all important things to consider - \\n- 1. Action : \\n - The action is what the agent might be doing or did in their task during the environment mission. \\n- 2. Communication : \\n - The communication transmitted from agent in the video shared with either of medic, transporter or engineer. \\n It's not neccessary that every second there will be a key event so you can just say that nothing is happening in the video. Example JSON Response -\\n{timestamp: \"00:03\", \"action_state\":\"Engineer went into A2 Zone to help medic and destroyed rubble\"},{timestamp: \"00:09\", \"action_state\":\"Medic was just communicating but did nothing from its side\"}\"\"\"\n",
    "action_state_fusor_model_instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Model\n",
    "\n",
    "Consideres all important data and gives score to each intervention's team and asi advice with reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a professional teamwork scorer. Your job is to analyze a data having various properties of the data to give . You have to rate the team work score to the team, You have to be impartial and a critique like a professional. The data is about a minecraft test bed rescue simulation where three agents named Engineer, Medic and Transporter work and communicate with each other to rescue victims from threat rooms. Here is some information about the agents :\\n1. Engineer : Engineer agent wears blue skin while medic wears red and transporter wears green skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there\\'s a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there\\'s a threat room nearby for others to be aware.\\nc) Destroying rubles for making way for rescue teammates.\\n2. Transporter :  Transporter agent wears green skin while engineer wears blue and medic wears red skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there\\'s a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there\\'s a threat room nearby for others to be aware.\\nc) Transporting victims from location to location.\\nd) Standing on wifi signal block to detect victims nearby.\\n3. Medic : Medic agent wears red skin while engineer wears blue and transporter wears green skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there\\'s a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there\\'s a threat room nearby for others to be aware.\\nc) Stabilizing avatar victim blocks turning into safe blocks\\nd) Stabilizing avatar victim blocks turning into X blocks notifying victim is dead. \\nHere are all important things to consider - \\n- 1. Action : \\n - The action is what the agent might be doing or did in their task during the environment mission. \\n- 2. Communication : \\n - The communication transmitted from agent in the video shared with either of medic, transporter or engineer. Example JSON Response -\\n{timestamp: \"00:03\", \"team_score\":\"76\", \"reason:\" \"Engineer went into A2 Zone to help medic and destroyed rubble, Medic stabilized a victim and rushed to transporter, very quickly in this way the team work was good\"}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_model_instruction = \"\"\"You are a professional teamwork scorer. Your job is to analyze a data having various properties of the data to give . You have to rate the team work score to the team, You have to be impartial and a critique like a professional. The data is about a minecraft test bed rescue simulation where three agents named Engineer, Medic and Transporter work and communicate with each other to rescue victims from threat rooms. Here is some information about the agents :\\n1. Engineer : Engineer agent wears blue skin while medic wears red and transporter wears green skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\\nc) Destroying rubles for making way for rescue teammates.\\n2. Transporter :  Transporter agent wears green skin while engineer wears blue and medic wears red skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\\nc) Transporting victims from location to location.\\nd) Standing on wifi signal block to detect victims nearby.\\n3. Medic : Medic agent wears red skin while engineer wears blue and transporter wears green skin. Key events- \\na) Placing Avatar Yellow Marker Block for notifying there's a victim nearby for others to be aware. \\nb)Placing Blank Yellow Marker Block for notifying there's a threat room nearby for others to be aware.\\nc) Stabilizing avatar victim blocks turning into safe blocks\\nd) Stabilizing avatar victim blocks turning into X blocks notifying victim is dead. \\nHere are all important things to consider - \\n- 1. Action : \\n - The action is what the agent might be doing or did in their task during the environment mission. \\n- 2. Communication : \\n - The communication transmitted from agent in the video shared with either of medic, transporter or engineer. Example JSON Response -\\n{timestamp: \"00:03\", \"team_score\":\"76\", \"reason:\" \"Engineer went into A2 Zone to help medic and destroyed rubble, Medic stabilized a victim and rushed to transporter, very quickly in this way the team work was good\"}\"\"\"\n",
    "scoring_model_instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcript.csv analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/ash/CHART ASIST/data/transcripts/TM000297.csv\")\n",
    "df = df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Intervention Message</th>\n",
       "      <th>Intervention Recipient</th>\n",
       "      <th>Speech Message</th>\n",
       "      <th>Medic</th>\n",
       "      <th>Transporter</th>\n",
       "      <th>Engineer</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>22:27:34</td>\n",
       "      <td>Hello, I am ATLAS, and will be providing advic...</td>\n",
       "      <td>['E001001', 'E001146', 'E001064']</td>\n",
       "      <td>{}</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>{'info': {'intervention_class': 'TeamWelcomeMe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>22:27:55</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>people is be advised there is some wield damag...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>22:28:06</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>okay so this is medic my plan is I'm going to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>22:28:07</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>22:28:10</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>copy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Timestamp                               Intervention Message  \\\n",
       "1  2022-06-27  22:27:34  Hello, I am ATLAS, and will be providing advic...   \n",
       "2  2022-06-27  22:27:55                                                 {}   \n",
       "3  2022-06-27  22:28:06                                                 {}   \n",
       "4  2022-06-27  22:28:07                                                 {}   \n",
       "5  2022-06-27  22:28:10                                                 {}   \n",
       "\n",
       "              Intervention Recipient  \\\n",
       "1  ['E001001', 'E001146', 'E001064']   \n",
       "2                                 {}   \n",
       "3                                 {}   \n",
       "4                                 {}   \n",
       "5                                 {}   \n",
       "\n",
       "                                      Speech Message  Medic  Transporter  \\\n",
       "1                                                 {}      1            1   \n",
       "2  people is be advised there is some wield damag...      0            0   \n",
       "3  okay so this is medic my plan is I'm going to ...      1            0   \n",
       "4                                                yes      0            1   \n",
       "5                                               copy      0            0   \n",
       "\n",
       "   Engineer                                        Explanation  \n",
       "1         1  {'info': {'intervention_class': 'TeamWelcomeMe...  \n",
       "2         1                                                 {}  \n",
       "3         0                                                 {}  \n",
       "4         0                                                 {}  \n",
       "5         1                                                 {}  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Data\n",
    "\n",
    "Originally it had many columns and we reduced it down to only the ones which had data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'intervention_message'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'intervention_message'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33masi_message\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mintervention_message\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.replace(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mteam_message\u001b[39m\u001b[33m\"\u001b[39m] = df[\u001b[33m\"\u001b[39m\u001b[33mspeech_message\u001b[39m\u001b[33m\"\u001b[39m].replace(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/venv/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'intervention_message'"
     ]
    }
   ],
   "source": [
    "df[\"asi_message\"] = df[\"intervention_message\"].replace(\"{}\", \"\")\n",
    "df[\"team_message\"] = df[\"speech_message\"].replace(\"{}\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a intervention_class column from explanation string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract intervention_class from explanation strings\n",
    "df['intervention_class'] = df['explanation'].str.extract(\n",
    "    r\"'intervention_class'\\s*:\\s*'([^']*)'\"\n",
    ")\n",
    "\n",
    "# Create binary columns for each unique intervention class\n",
    "intervention_classes = df['intervention_class'].dropna().unique()\n",
    "for cls in intervention_classes:\n",
    "    df[cls] = df['intervention_class'].eq(cls).astype(int)\n",
    "\n",
    "# Cleanup intermediate column\n",
    "df = df.drop(columns=['intervention_class'])\n",
    "\n",
    "# Clean column names by removing 'Intervention' suffix\n",
    "df = df.rename(columns=lambda col: col[:-13] if col.endswith('Intervention') else col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need unique team ids, asi ids, date, trial id, intervention_recipent id or explanation since we have extracted the unique class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop(columns=[\"team\",\"asi\",\"date\",\"intervention_recipent\",\"intervention_message\",\"speech_message\",\"trial\"], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Drop duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player's POV LLM Data Analysis - Multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Gemini [Multimodal book](https://colab.research.google.com/drive/1eXv-lpq9Lp4s2Vf2ISmSEngMJnVMOBRk?usp=sharing#scrollTo=A0zpRFCI-weC) to setup instruct models for [analysis](https://aistudio.google.com/app/starter-apps/video)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp\n",
    "\n",
    "df = pd.read_csv(\"/mnt/c/Users/Som/Desktop/CHART ASIST/temp.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Player model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with video: data/video/TM000297/experiment_1/engineer/pov/chunk_1/chunk_1.mp4\n",
      "File uploaded: files/twxaf5271uyn\n",
      "File state: FileState.PROCESSING\n",
      "Waiting for file processing...\n",
      "File state: FileState.ACTIVE\n",
      "File is now active and ready for processing\n",
      "Response received:\n",
      "[\n",
      "  {\"timestamp\": \"00:00\", \"text\": \"Engineer is walking through a doorway\"},\n",
      "  {\"timestamp\": \"00:03\", \"text\": \"Engineer is walking down the hallway\"},\n",
      "  {\"timestamp\": \"00:06\", \"text\": \"Engineer is walking down the hallway\"},\n",
      "  {\"timestamp\": \"00:09\", \"text\": \"Engineer is walking down the hallway\"}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "from google import genai\n",
    "from google.genai.types import GenerateContentConfig, HttpOptions\n",
    "\n",
    "# Initialize the client\n",
    "genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "MODEL_ID = 'gemini-2.0-flash-exp'\n",
    "\n",
    "# Define a test video path - use a specific video file that exists\n",
    "test_video_path = Path(\"data/video/TM000297/experiment_1/engineer/pov/chunk_1/chunk_1.mp4\")\n",
    "\n",
    "# Test if the file exists\n",
    "if not test_video_path.exists():\n",
    "    print(f\"Test video not found: {test_video_path}\")\n",
    "else:\n",
    "    try:\n",
    "        print(f\"Testing with video: {test_video_path}\")\n",
    "        \n",
    "        # Upload the video to Gemini\n",
    "        file_upload = genai_client.files.upload(file=str(test_video_path))\n",
    "        print(f\"File uploaded: {file_upload.name}\")\n",
    "        \n",
    "        # Wait for file to be processed (ACTIVE state)\n",
    "        max_retries = 10\n",
    "        retry_count = 0\n",
    "        while retry_count < max_retries:\n",
    "            # Check file status\n",
    "            file_info = genai_client.files.get(name=file_upload.name)\n",
    "            print(f\"File state: {file_info.state}\")\n",
    "            \n",
    "            if file_info.state == \"ACTIVE\":\n",
    "                print(f\"File is now active and ready for processing\")\n",
    "                break\n",
    "            \n",
    "            print(\"Waiting for file processing...\")\n",
    "            time.sleep(5)\n",
    "            retry_count += 1\n",
    "        \n",
    "        if retry_count == max_retries:\n",
    "            print(\"File processing timed out\")\n",
    "        else:\n",
    "            # Generate content with a simplified instruction\n",
    "            test_instruction = \"Please Follow the guidelines. Here is the video. RESPOND IN JSON FORMAT ONLY.\"\n",
    "            \n",
    "            response = genai_client.models.generate_content(\n",
    "                model=MODEL_ID,\n",
    "                config=GenerateContentConfig(\n",
    "                    system_instruction=[engineer_pov_model_instruction]\n",
    "                ),\n",
    "                contents=[\n",
    "                    {\"role\": \"user\", \"parts\": [\n",
    "                        {\"file_data\": {\"file_uri\": file_upload.uri, \"mime_type\": \"video/mp4\"}},\n",
    "                        {\"text\": test_instruction}\n",
    "                    ]}\n",
    "                ]\n",
    "            )\n",
    "            response_text= response.text\n",
    "            if \"```json\" in response_text:\n",
    "                response_text = response.text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            \n",
    "            print(response_text)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in test script: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Location test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "from google import genai\n",
    "from google.genai.types import GenerateContentConfig, HttpOptions\n",
    "\n",
    "# Initialize the client\n",
    "genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "MODEL_ID = 'gemini-2.0-flash-exp'\n",
    "\n",
    "# Define a test video path - use a specific video file that exists\n",
    "test_video_path = Path(\"data/video/TM000297/experiment_1/engineer/location/chunk_1/chunk_1.mp4\")\n",
    "\n",
    "# Test if the file exists\n",
    "if not test_video_path.exists():\n",
    "    print(f\"Test video not found: {test_video_path}\")\n",
    "else:\n",
    "    try:\n",
    "        print(f\"Testing with video: {test_video_path}\")\n",
    "        \n",
    "        # Upload the video to Gemini\n",
    "        file_upload = genai_client.files.upload(file=str(test_video_path))\n",
    "        print(f\"File uploaded: {file_upload.name}\")\n",
    "        \n",
    "        # Wait for file to be processed (ACTIVE state)\n",
    "        max_retries = 10\n",
    "        retry_count = 0\n",
    "        while retry_count < max_retries:\n",
    "            # Check file status\n",
    "            file_info = genai_client.files.get(name=file_upload.name)\n",
    "            print(f\"File state: {file_info.state}\")\n",
    "            \n",
    "            if file_info.state == \"ACTIVE\":\n",
    "                print(f\"File is now active and ready for processing\")\n",
    "                break\n",
    "            \n",
    "            print(\"Waiting for file processing...\")\n",
    "            time.sleep(5)\n",
    "            retry_count += 1\n",
    "        \n",
    "        if retry_count == max_retries:\n",
    "            print(\"File processing timed out\")\n",
    "        else:\n",
    "            # Generate content with a simplified instruction\n",
    "            test_instruction = \"Please Follow the guidelines. Here is the video. RESPOND IN JSON FORMAT ONLY.\"\n",
    "            \n",
    "            response = genai_client.models.generate_content(\n",
    "                model=MODEL_ID,\n",
    "                config=GenerateContentConfig(\n",
    "        system_instruction=[engineer_location_model_instruction\n",
    "        ]\n",
    "    ),\n",
    "                contents=[\n",
    "                    {\"role\": \"user\", \"parts\": [\n",
    "                        {\"file_data\": {\"file_uri\": file_upload.uri, \"mime_type\": \"video/mp4\"}},\n",
    "                        {\"text\": test_instruction}\n",
    "                    ]}\n",
    "                ]\n",
    "            )\n",
    "            response_text = response.text\n",
    "            if \"```json\" in response_text:\n",
    "                response_text = response.text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            \n",
    "            print(\"Response received:\")\n",
    "            print(response_text)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in test script: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineer POV Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/video/TM000297/experiment_1/engineer/pov/chunk_1/chunk_1.mp4\n",
      "File uploaded: files/n3cwe1hg5je5\n",
      "File state: FileState.PROCESSING\n",
      "Waiting for file processing...\n",
      "File state: FileState.ACTIVE\n",
      "File is now active and ready for processing\n",
      "Error generating content: The read operation timed out\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpx/_transports/default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpcore/_backends/sync.py:126\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    125\u001b[39m exc_map: ExceptionMapping = {socket.timeout: ReadTimeout, \u001b[38;5;167;01mOSError\u001b[39;00m: ReadError}\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/contextlib.py:162\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpcore/_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mReadTimeout\u001b[39m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 63\u001b[39m\n\u001b[32m     61\u001b[39m test_instruction = \u001b[33m\"\u001b[39m\u001b[33mPlease Follow the guidelines. Here is the video. RESPOND IN JSON FORMAT ONLY.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m response = \u001b[43mgenai_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_ID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGenerateContentConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m        \u001b[49m\u001b[43msystem_instruction\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengineer_pov_model_instruction\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile_data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile_uri\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_upload\u001b[49m\u001b[43m.\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmime_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvideo/mp4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_instruction\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m response_text= response.text\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/google/genai/models.py:4942\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   4941\u001b[39m i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m4942\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4943\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\n\u001b[32m   4944\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4945\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAFC remote call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is done.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/google/genai/models.py:3915\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   3913\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m3915\u001b[39m response_dict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3916\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   3917\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._api_client.vertexai:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/google/genai/_api_client.py:655\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m    652\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m    653\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m    654\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m json_response = response.json\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/google/genai/_api_client.py:577\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpx_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m      \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m      \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    584\u001b[39m   errors.APIError.raise_for_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpx/_client.py:825\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    812\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    813\u001b[39m     method=method,\n\u001b[32m    814\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    823\u001b[39m     extensions=extensions,\n\u001b[32m    824\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpx/_transports/default.py:249\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m    250\u001b[39m     resp = \u001b[38;5;28mself\u001b[39m._pool.handle_request(req)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/contextlib.py:162\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CHART ASIST/.venv/lib64/python3.13/site-packages/httpx/_transports/default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mReadTimeout\u001b[39m: The read operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 93\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     92\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Wait longer before retrying another file\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     96\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import time\n",
    "from google import genai\n",
    "import json\n",
    "from pathlib import Path\n",
    "from google.genai.types import GenerateContentConfig, HttpOptions\n",
    "\n",
    "# Initialize the client with extended timeout\n",
    "genai_client = genai.Client(\n",
    "    api_key=GEMINI_API_KEY,\n",
    "    http_options=HttpOptions(timeout=600)  # Extend timeout to 5 minutes\n",
    ")\n",
    "MODEL_ID = 'gemini-2.0-flash-exp'\n",
    "\n",
    "# Define the path to the engineer folder\n",
    "engineer_folder = Path(\"data/video/TM000297/experiment_1/engineer/pov\")\n",
    "\n",
    "# Loop over the chunks in the engineer folder\n",
    "for chunk_folder in engineer_folder.iterdir():\n",
    "    if chunk_folder.is_dir():\n",
    "        # Check if response already exists\n",
    "        response_file = chunk_folder / \"pov.json\"\n",
    "        if response_file.exists():\n",
    "            print(f\"Response already exists for {chunk_folder.name}, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        # Get the video file from the chunk folder\n",
    "        video_file = next(chunk_folder.glob(\"*.mp4\"), None)\n",
    "        if video_file:\n",
    "            print(f\"Processing {video_file}\")\n",
    "            \n",
    "            try:\n",
    "                # Upload the video to Gemini\n",
    "                try:\n",
    "                    file_upload = genai_client.files.upload(file=video_file)\n",
    "                    print(f\"File uploaded: {file_upload.name}\")\n",
    "                except Exception as upload_error:\n",
    "                    print(f\"Error uploading file: {upload_error}\")\n",
    "                    break\n",
    "                # Wait for file to be processed (ACTIVE state)\n",
    "                max_retries = 10  # Increase max retries\n",
    "                retry_count = 0\n",
    "                while retry_count < max_retries:\n",
    "                    # Check file status\n",
    "                    file_info = genai_client.files.get(name=file_upload.name)\n",
    "                    print(f\"File state: {file_info.state}\")\n",
    "                    \n",
    "                    if file_info.state == \"ACTIVE\":\n",
    "                        print(f\"File is now active and ready for processing\")\n",
    "                        break\n",
    "                    \n",
    "                    print(\"Waiting for file processing...\")\n",
    "                    time.sleep(5)\n",
    "                    retry_count += 1\n",
    "                \n",
    "                if retry_count == max_retries:\n",
    "                    print(\"File processing timed out\")\n",
    "                else:\n",
    "                    # Generate content with a simplified instruction\n",
    "                    test_instruction = \"Please Follow the guidelines. Here is the video. RESPOND IN JSON FORMAT ONLY.\"\n",
    "                    \n",
    "                    response = genai_client.models.generate_content(\n",
    "                        model=MODEL_ID,\n",
    "                        config=GenerateContentConfig(\n",
    "                            system_instruction=[engineer_pov_model_instruction]\n",
    "                        ),\n",
    "                        contents=[\n",
    "                            {\"role\": \"user\", \"parts\": [\n",
    "                                {\"file_data\": {\"file_uri\": file_upload.uri, \"mime_type\": \"video/mp4\"}},\n",
    "                                {\"text\": test_instruction}\n",
    "                            ]}\n",
    "                        ]\n",
    "                    )\n",
    "                    response_text= response.text\n",
    "                    if \"```json\" in response_text:\n",
    "                        response_text = response.text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                    \n",
    "                    with open(response_file, \"w\") as f:\n",
    "                        f.write(response_text)\n",
    "                    print(f\"Saved response to {response_file}\")\n",
    "                    # Add a cool-down period between API calls\n",
    "                    print(\"Cooling down for 30 seconds before next request...\")\n",
    "                    \n",
    "            except Exception as generate_error:\n",
    "                print(f\"Error generating content: {generate_error}\")\n",
    "                # Try to delete the file to free up resources\n",
    "                try:\n",
    "                    genai_client.files.delete(name=file_upload.name)\n",
    "                    print(f\"Deleted file {file_upload.name} after error\")\n",
    "                except:\n",
    "                    pass\n",
    "                time.sleep(60)  # Wait longer before retrying another file\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video_file}: {e}\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import time\n",
    "from google import genai\n",
    "import json\n",
    "\n",
    "# Initialize the client\n",
    "genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "MODEL_ID = 'gemini-2.0-flash-exp'\n",
    "\n",
    "# Define the path to the engineer folder\n",
    "engineer_folder = Path(\"data/video/TM000297/experiment_1/engineer/location\")\n",
    "\n",
    "# Loop over the chunks in the engineer folder\n",
    "for chunk_folder in engineer_folder.iterdir():\n",
    "    if chunk_folder.is_dir():\n",
    "        # Get the video file from the chunk folder\n",
    "        video_file = next(chunk_folder.glob(\"*.mp4\"), None)\n",
    "        if video_file:\n",
    "            print(f\"Processing {video_file}\")\n",
    "            \n",
    "            try:\n",
    "                # Upload the video to Gemini\n",
    "                with open(video_file, \"rb\") as f:\n",
    "                    file_bytes = f.read()\n",
    "                \n",
    "                file_upload = genai_client.files.upload(file=str(video_file))\n",
    "                \n",
    "                # Wait for file to be processed (ACTIVE state)\n",
    "                max_retries = 10\n",
    "                retry_count = 0\n",
    "                while retry_count < max_retries:\n",
    "                    # Check file status\n",
    "                    file_info = genai_client.files.get(name=file_upload.name)\n",
    "                    if file_info.state == \"ACTIVE\":\n",
    "                        print(f\"File {file_upload.name} is now active and ready\")\n",
    "                        break\n",
    "                    \n",
    "                    print(f\"File {file_upload.name} is in {file_info.state} state. Waiting...\")\n",
    "                    time.sleep(5)  # Wait 5 seconds before checking again\n",
    "                    retry_count += 1\n",
    "                \n",
    "                if retry_count == max_retries:\n",
    "                    print(f\"File {file_upload.name} did not become active. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Generate content using the uploaded file and the instruction\n",
    "                response = genai_client.models.generate_content(\n",
    "                    model=MODEL_ID,\n",
    "                    config=GenerateContentConfig(\n",
    "                        system_instruction=[engineer_location_model_instruction]\n",
    "                    ),\n",
    "                    contents=[\n",
    "                        {\"role\": \"user\", \"parts\": [\n",
    "                            {\"file_data\": {\"file_uri\": file_upload.uri, \"mime_type\": \"video/mp4\"}},\n",
    "                            {\"text\": \"Please Follow the guidelines. Here is the video. RESPOND IN JSON FORMAT ONLY.\"}\n",
    "                        ]}\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                response_text = response.text\n",
    "                \n",
    "                # Remove markdown code block syntax if present\n",
    "                if \"```json\" in response_text:\n",
    "                    response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                \n",
    "                # Save the response to the same chunk folder as a JSON file\n",
    "                response_file = chunk_folder / \"location.json\"\n",
    "                with open(response_file, \"w\") as f:\n",
    "                    json.dump(response_text, f)\n",
    "                print(f\"Saved response to {response_file}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medic POV Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import time\n",
    "from google import genai\n",
    "import json\n",
    "\n",
    "# Initialize the client\n",
    "genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "MODEL_ID = 'gemini-2.0-flash-exp'\n",
    "\n",
    "# Define the path to the engineer folder\n",
    "medic_folder = Path(\"data/video/TM000297/experiment_1/medic/pov\")\n",
    "\n",
    "# Loop over the chunks in the engineer folder\n",
    "for chunk_folder in medic_folder.iterdir():\n",
    "    if chunk_folder.is_dir():\n",
    "        # Get the video file from the chunk folder\n",
    "        video_file = next(chunk_folder.glob(\"*.mp4\"), None)\n",
    "        if video_file:\n",
    "            print(f\"Processing {video_file}\")\n",
    "            \n",
    "            try:\n",
    "                # Upload the video to Gemini\n",
    "                with open(video_file, \"rb\") as f:\n",
    "                    file_bytes = f.read()\n",
    "                \n",
    "                file_upload = genai_client.files.upload(file=str(video_file))\n",
    "                \n",
    "                # Wait for file to be processed (ACTIVE state)\n",
    "                max_retries = 10\n",
    "                retry_count = 0\n",
    "                while retry_count < max_retries:\n",
    "                    # Check file status\n",
    "                    file_info = genai_client.files.get(name=file_upload.name)\n",
    "                    if file_info.state == \"ACTIVE\":\n",
    "                        print(f\"File {file_upload.name} is now active and ready\")\n",
    "                        break\n",
    "                    \n",
    "                    print(f\"File {file_upload.name} is in {file_info.state} state. Waiting...\")\n",
    "                    time.sleep(5)  # Wait 5 seconds before checking again\n",
    "                    retry_count += 1\n",
    "                \n",
    "                if retry_count == max_retries:\n",
    "                    print(f\"File {file_upload.name} did not become active. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Generate content using the uploaded file and the instruction\n",
    "                response = genai_client.models.generate_content(\n",
    "                    model=MODEL_ID,\n",
    "                    config=GenerateContentConfig(\n",
    "                        system_instruction=[medic_pov_model_instruction]\n",
    "                    ),\n",
    "                    contents=[\n",
    "                        {\"role\": \"user\", \"parts\": [\n",
    "                            {\"file_data\": {\"file_uri\": file_upload.uri, \"mime_type\": \"video/mp4\"}},\n",
    "                            {\"text\": \"Please Follow the guidelines. Here is the video. RESPOND IN JSON FORMAT ONLY.\"}\n",
    "                        ]}\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                response_text = response.text\n",
    "                \n",
    "                # Remove markdown code block syntax if present\n",
    "                if \"```json\" in response_text:\n",
    "                    response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                \n",
    "                # Save the response to the same chunk folder as a JSON file\n",
    "                response_file = chunk_folder / \"pov.json\"\n",
    "                with open(response_file, \"w\") as f:\n",
    "                    json.dump(response_text, f)\n",
    "                print(f\"Saved response to {response_file}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import time\n",
    "from google import genai\n",
    "import json\n",
    "\n",
    "# Initialize the client\n",
    "genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "MODEL_ID = 'gemini-2.0-flash-exp'\n",
    "\n",
    "# Define the path to the engineer folder\n",
    "medic_folder = Path(\"data/video/TM000297/experiment_1/medic/location\")\n",
    "\n",
    "# Loop over the chunks in the engineer folder\n",
    "for chunk_folder in medic_folder.iterdir():\n",
    "    if chunk_folder.is_dir():\n",
    "        # Get the video file from the chunk folder\n",
    "        video_file = next(chunk_folder.glob(\"*.mp4\"), None)\n",
    "        if video_file:\n",
    "            print(f\"Processing {video_file}\")\n",
    "            \n",
    "            try:\n",
    "                # Upload the video to Gemini\n",
    "                with open(video_file, \"rb\") as f:\n",
    "                    file_bytes = f.read()\n",
    "                \n",
    "                file_upload = genai_client.files.upload(file=str(video_file))\n",
    "                \n",
    "                # Wait for file to be processed (ACTIVE state)\n",
    "                max_retries = 10\n",
    "                retry_count = 0\n",
    "                while retry_count < max_retries:\n",
    "                    # Check file status\n",
    "                    file_info = genai_client.files.get(name=file_upload.name)\n",
    "                    if file_info.state == \"ACTIVE\":\n",
    "                        print(f\"File {file_upload.name} is now active and ready\")\n",
    "                        break\n",
    "                    \n",
    "                    print(f\"File {file_upload.name} is in {file_info.state} state. Waiting...\")\n",
    "                    time.sleep(5)  # Wait 5 seconds before checking again\n",
    "                    retry_count += 1\n",
    "                \n",
    "                if retry_count == max_retries:\n",
    "                    print(f\"File {file_upload.name} did not become active. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Generate content using the uploaded file and the instruction\n",
    "                response = genai_client.models.generate_content(\n",
    "                    model=MODEL_ID,\n",
    "                    config=GenerateContentConfig(\n",
    "                        system_instruction=[medic_location_model_instruction]\n",
    "                    ),\n",
    "                    contents=[\n",
    "                        {\"role\": \"user\", \"parts\": [\n",
    "                            {\"file_data\": {\"file_uri\": file_upload.uri, \"mime_type\": \"video/mp4\"}},\n",
    "                            {\"text\": \"Please Follow the guidelines. Here is the video. RESPOND IN JSON FORMAT ONLY.\"}\n",
    "                        ]}\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                response_text = response.text\n",
    "                \n",
    "                # Remove markdown code block syntax if present\n",
    "                if \"```json\" in response_text:\n",
    "                    response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                \n",
    "                # Save the response to the same chunk folder as a JSON file\n",
    "                response_file = chunk_folder / \"location.json\"\n",
    "                with open(response_file, \"w\") as f:\n",
    "                    json.dump(response_text, f)\n",
    "                print(f\"Saved response to {response_file}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transporter POV Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import time\n",
    "from google import genai\n",
    "import json\n",
    "\n",
    "# Initialize the client\n",
    "genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "MODEL_ID = 'gemini-2.0-flash-exp'\n",
    "\n",
    "# Define the path to the engineer folder\n",
    "transporter_folder = Path(\"data/video/TM000297/experiment_1/transporter/pov\")\n",
    "\n",
    "# Loop over the chunks in the engineer folder\n",
    "for chunk_folder in transporter_folder.iterdir():\n",
    "    if chunk_folder.is_dir():\n",
    "        # Get the video file from the chunk folder\n",
    "        video_file = next(chunk_folder.glob(\"*.mp4\"), None)\n",
    "        if video_file:\n",
    "            print(f\"Processing {video_file}\")\n",
    "            \n",
    "            try:\n",
    "                # Upload the video to Gemini\n",
    "                with open(video_file, \"rb\") as f:\n",
    "                    file_bytes = f.read()\n",
    "                \n",
    "                file_upload = genai_client.files.upload(file=str(video_file))\n",
    "                \n",
    "                # Wait for file to be processed (ACTIVE state)\n",
    "                max_retries = 10\n",
    "                retry_count = 0\n",
    "                while retry_count < max_retries:\n",
    "                    # Check file status\n",
    "                    file_info = genai_client.files.get(name=file_upload.name)\n",
    "                    if file_info.state == \"ACTIVE\":\n",
    "                        print(f\"File {file_upload.name} is now active and ready\")\n",
    "                        break\n",
    "                    \n",
    "                    print(f\"File {file_upload.name} is in {file_info.state} state. Waiting...\")\n",
    "                    time.sleep(5)  # Wait 5 seconds before checking again\n",
    "                    retry_count += 1\n",
    "                \n",
    "                if retry_count == max_retries:\n",
    "                    print(f\"File {file_upload.name} did not become active. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Generate content using the uploaded file and the instruction\n",
    "                response = genai_client.models.generate_content(\n",
    "                    model=MODEL_ID,\n",
    "                    config=GenerateContentConfig(\n",
    "                        system_instruction=[transporter_pov_model_instruction]\n",
    "                    ),\n",
    "                    contents=[\n",
    "                        {\"role\": \"user\", \"parts\": [\n",
    "                            {\"file_data\": {\"file_uri\": file_upload.uri, \"mime_type\": \"video/mp4\"}},\n",
    "                            {\"text\": \"Please Follow the guidelines. Here is the video. RESPOND IN JSON FORMAT ONLY.\"}\n",
    "                        ]}\n",
    "                    ]\n",
    "                )\n",
    "                response_text = response.text\n",
    "                \n",
    "                # Remove markdown code block syntax if present\n",
    "                if \"```json\" in response_text:\n",
    "                    response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                # Save the response to the same chunk folder as a JSON file\n",
    "                response_file = chunk_folder / \"pov.json\"\n",
    "                with open(response_file, \"w\") as f:\n",
    "                    json.dump(response_text, f)\n",
    "                print(f\"Saved response to {response_file}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import time\n",
    "from google import genai\n",
    "import json\n",
    "\n",
    "# Initialize the client\n",
    "genai_client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "MODEL_ID = 'gemini-2.0-flash-exp'\n",
    "\n",
    "# Define the path to the engineer folder\n",
    "transporter_folder = Path(\"data/video/TM000297/experiment_1/transporter/location\")\n",
    "\n",
    "# Loop over the chunks in the engineer folder\n",
    "for chunk_folder in transporter_folder.iterdir():\n",
    "    if chunk_folder.is_dir():\n",
    "        # Get the video file from the chunk folder\n",
    "        video_file = next(chunk_folder.glob(\"*.mp4\"), None)\n",
    "        if video_file:\n",
    "            print(f\"Processing {video_file}\")\n",
    "            \n",
    "            try:\n",
    "                # Upload the video to Gemini\n",
    "                with open(video_file, \"rb\") as f:\n",
    "                    file_bytes = f.read()\n",
    "                \n",
    "                file_upload = genai_client.files.upload(file=str(video_file))\n",
    "                \n",
    "                # Wait for file to be processed (ACTIVE state)\n",
    "                max_retries = 10\n",
    "                retry_count = 0\n",
    "                while retry_count < max_retries:\n",
    "                    # Check file status\n",
    "                    file_info = genai_client.files.get(name=file_upload.name)\n",
    "                    if file_info.state == \"ACTIVE\":\n",
    "                        print(f\"File {file_upload.name} is now active and ready\")\n",
    "                        break\n",
    "                    \n",
    "                    print(f\"File {file_upload.name} is in {file_info.state} state. Waiting...\")\n",
    "                    time.sleep(5)  # Wait 5 seconds before checking again\n",
    "                    retry_count += 1\n",
    "                \n",
    "                if retry_count == max_retries:\n",
    "                    print(f\"File {file_upload.name} did not become active. Skipping.\")\n",
    "                    continue\n",
    "                \n",
    "                # Generate content using the uploaded file and the instruction\n",
    "                response = genai_client.models.generate_content(\n",
    "                    model=MODEL_ID,\n",
    "                    config=GenerateContentConfig(\n",
    "                        system_instruction=[transporter_location_model_instruction]\n",
    "                    ),\n",
    "                    contents=[\n",
    "                        {\"role\": \"user\", \"parts\": [\n",
    "                            {\"file_data\": {\"file_uri\": file_upload.uri, \"mime_type\": \"video/mp4\"}},\n",
    "                            {\"text\": \"Please Follow the guidelines. Here is the video. RESPOND IN JSON FORMAT ONLY.\"}\n",
    "                        ]}\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                response_text = response.text\n",
    "                \n",
    "                # Remove markdown code block syntax if present\n",
    "                if \"```json\" in response_text:\n",
    "                    response_text = response_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "                \n",
    "                # Save the response to the same chunk folder as a JSON file\n",
    "                response_file = chunk_folder / \"location.json\"\n",
    "                with open(response_file, \"w\") as f:\n",
    "                    json.dump(response_text, f)\n",
    "                print(f\"Saved response to {response_file}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {video_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract JSON action_states to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_action_states = pd.DataFrame([\"timestamp\",\"engineer_action_state\",\"medic_action_state\",\"transporter_action_state\"])\n",
    "# merge df_action_states to df dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion LLM Text Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Objective\n",
    "\n",
    "Use LLM to analyze each agent's communication, location and state to form one [agent]_action_state \n",
    "\n",
    "**1. Map State**-\n",
    "\n",
    "Location of the agent in the map -> Room Name\n",
    "\n",
    "**2. Agent Action**-\n",
    "\n",
    "1. chat\n",
    "2. door\n",
    "3. ItemDrop\n",
    "4. ItemEquipped\n",
    "5. ItemPickup\n",
    "6. ItemUsed\n",
    "7. Lever\n",
    "8. PlayerJumped\n",
    "9. PlayerSprinting\n",
    "10. Scoreboard\n",
    "11. Triage\n",
    "12. RoleSelected\n",
    "13. ProximityBlockInteraction\n",
    "14. PlayerFrozenStateChange\n",
    "15. ToolUsed\n",
    "16. CompetencyTask\n",
    "17. TrainingTask\n",
    "18. ToolDepleted\n",
    "19. MarkerPlaced\n",
    "20. MarkerRemoved\n",
    "21. RubbleCollapse\n",
    "22. VictimEvacuated\n",
    "23. VictimPickedUp\n",
    "24. VictimPlaced\n",
    "25. RubbleDestroyed\n",
    "26. Signal\n",
    "27. Pause\n",
    "28. MissionState\n",
    "29. Perturbation\n",
    "30. PlanningStage\n",
    "31. PerturbationRubbleLocations\n",
    "32. location\n",
    "33. proximity\n",
    "34. dyad\n",
    "35. VictimsExpired\n",
    "36. PuzzleTextSummary\n",
    "37. dialogue_event\n",
    "38. TrialState\n",
    "\n",
    "**3. Agent Message**-\n",
    "\n",
    "Raw message extracted from transcript.csv\n",
    "\n",
    "### Prompt for AI Modal \n",
    "\n",
    "You are \n",
    "\n",
    "### Response Type\n",
    "\n",
    "```json\n",
    "{\n",
    "    agent: \"engineer | transporter | medic | victim\", [agent]_action_state \" [Agent] was likely doing this at this location \" \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass each row to LLM and retreive JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert JSON to a single dataframe of csv -> [agent]_action_state and append it to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score LLM Text Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Objective\n",
    "\n",
    "Use LLM to analyze agent's advice and team's communication and collaboration to form team_score and asi_advice score\n",
    "\n",
    "| timestamp | asi_reason | asi_action | transporter_message | engineer_message | medic_message | transporter_action_state | engineer_action_state | medic_action_state | victim_location | \n",
    "| --------- | --------- | --------- | ------------------ | --------------- | ------------ | --------------- | --------------- | ------------ | --------------- |\n",
    "|           |           |           |                    |                 |              |                 |                 |              |                 |\n",
    "\n",
    "### Prompt for AI Modal \n",
    "\n",
    "You are \n",
    "\n",
    "### Response Type\n",
    "\n",
    "```json\n",
    "{\n",
    "    asi_advice_score: \"number %\", team_score : \"number %\" \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass each row to LLM and retreive JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert JSON to a single dataframe of csv -> team_score and asi_advice score and append it to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
