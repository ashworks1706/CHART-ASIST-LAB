{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Modal Data Analysis Workflow\n",
    "\n",
    "**ASIST Study 3 Dataset**\n",
    "\n",
    "#### **Team 000315 Pre-Result Analysis**\n",
    "\n",
    "Engineer exibited poor skill during the hands on training. It took him a very long time to complete the individual training which resulted in the mission timer running out during the team training section. Once the timer expired, the hands-on training trial was restarted and participants again completed the individual training. Engineer's second attempt still took over 5 minutes to complete individual training. The competency test was then started at 13m remaining on the timer, the engineer took a full 5 minutes to complete the competency test. Experiment team decided that engineer should be allowed to proceed to avoid rescheduling dispite the evident lack of minecraft skill.\n",
    "\n",
    "## Objective\n",
    "\n",
    "Analyze team performance data across four modalities:\n",
    "\n",
    "1. JSON behavior logs\n",
    "2. Video recordings\n",
    "3. Chat transcripts\n",
    "\n",
    "Identify correlations between AI interventions and team outcomes.\n",
    "\n",
    "## Note\n",
    "\n",
    "All datasets were taken from official CHART ASIST Study 3 Dataset available at ASU official repository.\n",
    "\n",
    "#### Subset used :\n",
    "\n",
    "| Team ID | ASI ID        | trial   | intervention_recipent     |\n",
    "| ------- | ------------- | ------- | ------------------------- |\n",
    "| 000315  | ASI-CMURI-TA1 | T000829 | E001211, E001215, E001155 |\n",
    "\n",
    "\n",
    "\n",
    "**AI Agent Action signals** -\n",
    "\n",
    "1. RemindTransporterBeep\n",
    "2. InformAboutTriagedVictim\n",
    "3. RemindMedicToInformAboutTriagedVicti\n",
    "4. TriageCriticalVictim\n",
    "5. EvacuateCriticalVictim\n",
    "6. EncouragePlayerProximityToMedicIHMCDyad\n",
    "7. RemindChangeMarke\n",
    "8. RemindRubblePerturbatio\n",
    "9. EvacuationZoneDistanc\n",
    "10. TeamSawVictimMarke\n",
    "11. TimeElapse\n",
    "12. StartEvacuatio\n",
    "\n",
    "**Agents location**-\n",
    "\n",
    "1. Location of the agent in the map -> Room Name\n",
    "\n",
    "**Agent Action**-\n",
    "\n",
    "1. Transporting victims\n",
    "2. Performing their role task including stabilizing victims\n",
    "3. wakening up critical victims\n",
    "4. placing marking block-> Regular, A, B, C\n",
    "5. placing marking block for threat rooms\n",
    "6. removing rubbles\n",
    "7. detecting victims\n",
    "\n",
    "## V1 Dataframe\n",
    "\n",
    "Timestamp, AI Message, AI Action Class, Transporter Message, Engineer Message, Medic Message is extracted from transcript.csv\n",
    "\n",
    "We use Multimodal LLM analysis to analyze video data to give states and locations of agents + victims throughout the experiment\n",
    "\n",
    "States tells us what the agent is doing\n",
    "Locations tells use where the agent is located in the map\n",
    "\n",
    "| Time Stamp (Transcript) | Asi Message (Transcript) | Asi Action Class (Transcript) | Transporter Message (Transcript) | Engineer Message (Transcript) | Medic Message (Transcript) | Transporter State (LLM) | Engineer State (LLM) | Medic State (LLM) | Transporter location (LLM) | Engineer location (LLM) | Medic location (LLM) | Victim Location (LLM) |\n",
    "| ---------- | ----------- | ---------------- | ------------------- | ---------------- | ------------- | ----------------- | -------------- | ----------- | -------------------- | ----------------- | -------------- | --------------- |\n",
    "| 11:23:01   | N/A         | N/A              | N/A                 | N/A              | N/A           | N/A               | N/A            | N/A         | N/A                  | N/A               | N/A            | N/A             |\n",
    "\n",
    "## Final Dataframe\n",
    "\n",
    "States and locations are fused together using LLM analysis to form one action_state column signifying their role in a situation\n",
    "\n",
    "| timestamp (Transcript) | asi_reason (Transcript) | asi_action (Transcript) | transporter_message (Transcript) | engineer_message (Transcript) | medic_message (Transcript) | transporter_action_state (LLM) | engineer_action_state (LLM) | medic_action_state (LLM) | victim_location (LLM) | \n",
    "| --------- | --------- | --------- | ------------------ | --------------- | ------------ | --------------- | --------------- | ------------ | --------------- |\n",
    "|           |           |           |                    |                 |              |                 |                 |              |                 |\n",
    "\n",
    "\n",
    "We then utilize another LLM to finally provide ASI Advice score and team score for their actions and LLM's reasoning behiind that\n",
    "\n",
    "| timestamp (Transcript) | asi_reason (Transcript) | asi_action (Transcript) | transporter_message (Transcript) | engineer_message (Transcript) | medic_message (Transcript) | transporter_action_state (LLM) | engineer_action_state (LLM) | medic_action_state (LLM) | victim_location (LLM) | team_score (LLM) | asi_advice_score (LLM) | team_score_reason (LLM) | asi_advice_score_reason (LLM)\n",
    "| --------- | --------- | --------- | ------------------ | --------------- | ------------ | --------------- | ---------- | --------------- | --------------- |--------------- |--------------- | --------------- | --------------- |\n",
    "|     22:03      |   You guys should do [asi_action_class] because...        | 1. RemindTransporterBeep <br/>2. InformAboutTriagedVictim <br/>3. RemindMedicToInformAboutTriagedVicti <br/>4. TriageCriticalVictim <br/>5. EvacuateCriticalVictim <br/>6.EncouragePlayerProximityToMedicIHMCDyad <br/>7. RemindChangeMarke <br/>8. RemindRubblePerturbatio <br/>9. EvacuationZoneDistanc <br/>10. TeamSawVictimMarke <br/>11. TimeElapse <br/>12. StartEvacuatio|     I'm coming for you medic               |     This is more important               |     I can't help you!               |     Carrying a victim from b4 to g4 room               |     Clearing rubbles in threat room for medic  at a9 room          |     waking up critical victim at g5 room        |    next to medic, far from engineer, close to transporter            |  40%          |     75%           | team was inconsistent with their tasks, especially... | asi's advice is particularly useful because... |\n",
    "\n",
    "\n",
    "## AI Instruct Modal\n",
    "\n",
    "We finetune pretrained LLM on our data for understanding minecraft test bed for asist thoroughly and deeply. Then we utilize it to perform-\n",
    "\n",
    "1. **Multimodal DataAnalysis of Video Data** \n",
    "\n",
    "To give information about agent locations and their actions\n",
    "\n",
    "2. **Text Fusion Data Analysis**\n",
    "\n",
    "To fuse meanings and relationships between agent communication, their location and state in given situations to a single column\n",
    "\n",
    "3. **Scoring Analysis**\n",
    "\n",
    "To score humans and ASI's advice on team work communication and collaboration data   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "# import openai\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "# import torch\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. JSON Logs Processing\n",
    "#### Objective\n",
    "Extract structured data from nested JSON logs containing:\n",
    "- Team actions\n",
    "- AI intervention timestamps\n",
    "- Mission outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def parse_json_logs(input_path: Path, output_path: Path) -> pd.DataFrame:\n",
    "#     \"\"\"Flatten nested JSON logs into structured format\"\"\"\n",
    "#     with open(input_path, 'r') as f:\n",
    "#         data = [json.loads(line) for line in f]\n",
    "    \n",
    "#     df = pd.json_normalize(data, sep='_')\n",
    "#     df.to_csv(output_path, index=False)\n",
    "#     return df\n",
    "\n",
    "# # Process all trial messages\n",
    "# input_files = [\n",
    "#     Path(\"data/json_logs/HSRData_TrialMessages_Trial-T000603_...\"),\n",
    "#     Path(\"data/json_logs/HSRData_TrialMessages_Trial-T000639_...\"),\n",
    "#     Path(\"data/json_logs/HSRData_TrialMessages_Trial-T000671_...\")\n",
    "# ]\n",
    "\n",
    "# output_dir = Path(\"data/processed/json_parsed/\")\n",
    "# output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# for file in input_files:\n",
    "#     output_file = output_dir / f\"{file.stem}_parsed.csv\"\n",
    "#     df = parse_json_logs(file, output_file)\n",
    "#     print(f\"Processed {len(df)} records from {file.name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Finetuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective \n",
    "\n",
    "Finetune the pretrained instruct model on testbed refined high quality data and information about agents, environment, locations. \n",
    "\n",
    "[ Maybe : Train model to understand video data as well ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineer Instruct POV Model\n",
    "\n",
    "Finetune the pretrained instruct model on testbed refined high quality data and information about agents actions in minecraft video. \n",
    "\n",
    "[ Maybe : Train model to understand video data as well ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medic Instruct POV \n",
    "\n",
    "Finetune the pretrained instruct model on testbed refined high quality data and information about agents actions in minecraft video. \n",
    "\n",
    "[ Maybe : Train model to understand video data as well ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transporter Instruct POV Model\n",
    "\n",
    "\n",
    "Finetune the pretrained instruct model on testbed refined high quality data and information about agents actions in minecraft video. \n",
    "\n",
    "[ Maybe : Train model to understand video data as well ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenter's Map Instruct Model\n",
    "\n",
    "\n",
    "Finetune the pretrained instruct model on testbed refined high quality data and information about victim locations and agent locations in live map. \n",
    "\n",
    "[ Maybe : Train model to understand video data as well ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Player's Action State Fusor Model\n",
    "\n",
    "\n",
    "Fuses player actions and their location in maps to form a rich action state data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Model\n",
    "\n",
    "Consideres all important data and gives score to each intervention's team and asi advice with reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcript.csv analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/c/Users/Som/Desktop/CHART ASIST/Study3_Analysis/data/transcripts/transcript.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/mnt/c/Users/Som/Desktop/CHART ASIST/Study3_Analysis/data/transcripts/transcript.csv\")\n",
    "df = df[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Data\n",
    "\n",
    "Originally it had many columns and we reduced it down to only the ones which had data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"asi_message\"] = df[\"intervention_message\"].replace(\"{}\", \"\")\n",
    "df[\"team_message\"] = df[\"speech_message\"].replace(\"{}\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a intervention_class column from explanation string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract intervention_class from explanation strings\n",
    "df['intervention_class'] = df['explanation'].str.extract(\n",
    "    r\"'intervention_class'\\s*:\\s*'([^']*)'\"\n",
    ")\n",
    "\n",
    "# Create binary columns for each unique intervention class\n",
    "intervention_classes = df['intervention_class'].dropna().unique()\n",
    "for cls in intervention_classes:\n",
    "    df[cls] = df['intervention_class'].eq(cls).astype(int)\n",
    "\n",
    "# Cleanup intermediate column\n",
    "df = df.drop(columns=['intervention_class'])\n",
    "\n",
    "# Clean column names by removing 'Intervention' suffix\n",
    "df = df.rename(columns=lambda col: col[:-13] if col.endswith('Intervention') else col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need unique team ids, asi ids, date, trial id, intervention_recipent id or explanation since we have extracted the unique class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop(columns=[\"team\",\"asi\",\"date\",\"intervention_recipent\",\"intervention_message\",\"speech_message\",\"trial\"], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Drop duplicated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenter's Map LLM Data Analysis - Multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective -\n",
    "\n",
    "Analyzing gameplay videos with AI, to output -\n",
    "\n",
    "**1. Agents location**-\n",
    "\n",
    "1. Location of the agent in the map -> Room Name\n",
    "\n",
    "**2. Victims location**-\n",
    "\n",
    "### Prompt for AI Modal \n",
    "\n",
    "You are \n",
    "\n",
    "### Response Type\n",
    "\n",
    "```json\n",
    "{\n",
    "    agent: \"engineer | transporter | medic | victim\", location: \"roomb12|roomh12...\"\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the video in 25ms parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : Use ffmpeg to divide videos into frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass video chunks to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## call modal apis and retreive json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Json to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the json to csv column -> States and Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Player's POV LLM Data Analysis - Multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective -\n",
    "\n",
    "Analyzing gameplay videos with AI, to output -\n",
    "\n",
    "**1. Agent actions**\n",
    "\n",
    "### Prompt for AI Modal \n",
    "\n",
    "You are \n",
    "\n",
    "### Response Type\n",
    "\n",
    "```json\n",
    "{\n",
    "    agent: \"engineer | transporter | medic | victim\", action: \"chat|door|ItemDrop|ItemEquipped|ItemPickup|ItemUsed|Lever|PlayerJumped|PlayerSprinting|Triage|ProximityBlockInteraction|ToolUsed|CompetencyTask\n",
    "|ToolDepleted|MarkerPlaced|MarkerRemoved|RubbleCollapse|VictimEvacuated|VictimPickedUp|VictimPlaced|RubbleDestroyed|PerturbationRubbleLocations\n",
    "|VictimsExpired\"\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the video in 25ms parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : Use ffmpeg to divide videos into frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass video chunks to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## call modal apis and retreive json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Json to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the json to csv column -> States and Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion LLM Text Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Objective\n",
    "\n",
    "Use LLM to analyze each agent's communication, location and state to form one [agent]_action_state \n",
    "\n",
    "**1. Map State**-\n",
    "\n",
    "Location of the agent in the map -> Room Name\n",
    "\n",
    "**2. Agent Action**-\n",
    "\n",
    "1. chat\n",
    "2. door\n",
    "3. ItemDrop\n",
    "4. ItemEquipped\n",
    "5. ItemPickup\n",
    "6. ItemUsed\n",
    "7. Lever\n",
    "8. PlayerJumped\n",
    "9. PlayerSprinting\n",
    "10. Scoreboard\n",
    "11. Triage\n",
    "12. RoleSelected\n",
    "13. ProximityBlockInteraction\n",
    "14. PlayerFrozenStateChange\n",
    "15. ToolUsed\n",
    "16. CompetencyTask\n",
    "17. TrainingTask\n",
    "18. ToolDepleted\n",
    "19. MarkerPlaced\n",
    "20. MarkerRemoved\n",
    "21. RubbleCollapse\n",
    "22. VictimEvacuated\n",
    "23. VictimPickedUp\n",
    "24. VictimPlaced\n",
    "25. RubbleDestroyed\n",
    "26. Signal\n",
    "27. Pause\n",
    "28. MissionState\n",
    "29. Perturbation\n",
    "30. PlanningStage\n",
    "31. PerturbationRubbleLocations\n",
    "32. location\n",
    "33. proximity\n",
    "34. dyad\n",
    "35. VictimsExpired\n",
    "36. PuzzleTextSummary\n",
    "37. dialogue_event\n",
    "38. TrialState\n",
    "\n",
    "**3. Agent Message**-\n",
    "\n",
    "Raw message extracted from transcript.csv\n",
    "\n",
    "### Prompt for AI Modal \n",
    "\n",
    "You are \n",
    "\n",
    "### Response Type\n",
    "\n",
    "```json\n",
    "{\n",
    "    agent: \"engineer | transporter | medic | victim\", [agent]_action_state \" [Agent] was likely doing this at this location \" \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass each row to LLM and retreive JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert JSON to a single dataframe of csv -> [agent]_action_state and append it to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score LLM Text Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Objective\n",
    "\n",
    "Use LLM to analyze agent's advice and team's communication and collaboration to form team_score and asi_advice score\n",
    "\n",
    "| timestamp | asi_reason | asi_action | transporter_message | engineer_message | medic_message | transporter_action_state | engineer_action_state | medic_action_state | victim_location | \n",
    "| --------- | --------- | --------- | ------------------ | --------------- | ------------ | --------------- | --------------- | ------------ | --------------- |\n",
    "|           |           |           |                    |                 |              |                 |                 |              |                 |\n",
    "\n",
    "### Prompt for AI Modal \n",
    "\n",
    "You are \n",
    "\n",
    "### Response Type\n",
    "\n",
    "```json\n",
    "{\n",
    "    asi_advice_score: \"number %\", team_score : \"number %\" \n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass each row to LLM and retreive JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert JSON to a single dataframe of csv -> team_score and asi_advice score and append it to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
